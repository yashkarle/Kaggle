{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeFEi8Nk5qpR"
   },
   "source": [
    "# Machine Learning in Python - MNIST Fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGf8cIml5qpR"
   },
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVLsL4rm5qpS"
   },
   "source": [
    "### Lots of Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "HVinCSc46yWk",
    "outputId": "70c5fade-735a-46c7-c63f-1b6d6a0e0dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/4d/fc83980735a7a2e3aaba1ed755462e839c68ba51ac311efdb1ab413a4eeb/kaggle-1.5.2.tar.gz (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 840kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from kaggle) (2018.11.29)\n",
      "Requirement already satisfied: python-dateutil in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from kaggle) (2.6.1)\n",
      "Requirement already satisfied: requests in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from kaggle) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from kaggle) (4.23.2)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/9c/8b07d625e9c9df567986d887f0375075abb1923e49d074a7803cd1527dae/python-slugify-2.0.1.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/bmacnamee/anaconda3/lib/python3.6/site-packages (from requests->kaggle) (2.6)\n",
      "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/bmacnamee/Library/Caches/pip/wheels/0d/58/eb/83d6a2e1935aff39d341ffa1e5faa3809e173cd0937e057d83\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/bmacnamee/Library/Caches/pip/wheels/2b/9e/c8/14a18ab55d8f144384de8186a3df8401dcc9264936f71d470f\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: Unidecode, python-slugify, kaggle\n",
      "Successfully installed Unidecode-1.0.23 kaggle-1.5.2 python-slugify-2.0.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Install Dependencies\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1LkxhwoCoKg"
   },
   "source": [
    "We need to Upload the our credentials of the Kaggle account in here befoew we could import any dataset. \n",
    "\n",
    "\n",
    "1.   Log into you Kaggle acount\n",
    "2.   Click on the \"your profile\" icon on the top right of the page\n",
    "3.   Click on My Account\n",
    "4.   Below the page click on Create New API Token\n",
    "\n",
    "The Kaggle.json file will be downloaded.\n",
    "\n",
    "Now you can run the code block down below and upload the Kaggle.json file from your PC onto Google Colab. This way you can automatically loginto your Kaggle account with no problem and seamlessly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "noq4yuPt7Fwl",
    "outputId": "49aa9736-7cfd-49e0-f546-5350e3c9ec93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-382991e5-8e93-4e52-b13f-253681f10459\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-382991e5-8e93-4e52-b13f-253681f10459\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"mehrandragon\",\"key\":\"251e5b5a01ce62e6017d8d4d64e7786e\"}'}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the credentials of the Kaggle account\n",
    "from google.colab import files\n",
    "files.upload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5yR32yS9h0v"
   },
   "outputs": [],
   "source": [
    "# Before importing the datasets we need to run the following code\n",
    "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "# This permissions change avoids a warning on Kaggle tool startup.\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cD1BXcfwCBGA"
   },
   "source": [
    "In order to download a dataset from Kaggle, we need the API Command for that dataset. to get it, choose the dataset of your interest on Kaggle, then choose \"**Copy API Command**\" and paste it here RIGHT after the exclamation mark down below . For example, for the  Fashion MNIST dataset the API command is: \n",
    "***kaggle datasets download -d zalando-research/fashionmnist***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "wW3vphSB9wXo",
    "outputId": "6db49c9b-dd40-4556-9ca2-eeae25afb0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fashionmnist.zip to /Users/bmacnamee/Dropbox/Teaching/UCD Advanced Machine Learning/2018-2019/Labs/Lab3a\n",
      " 16%|██████▏                                | 11.0M/68.8M [00:07<01:26, 698kB/s]/Users/bmacnamee/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|███████████████████████████████████████| 68.8M/68.8M [03:13<00:00, 348kB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we can import the dataset of interest\n",
    "!kaggle datasets download -d zalando-research/fashionmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WB6djSdv-nDQ",
    "outputId": "efd95543-d2a5-4c86-bf21-da2320aacfaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Machine_Learning_in_Python_MNIST_Fashion.ipynb\r\n",
      "\u001b[31mX_test.csv\u001b[m\u001b[m\r\n",
      "\u001b[31mX_train.csv\u001b[m\u001b[m\r\n",
      "\u001b[31msample_submission.csv\u001b[m\u001b[m\r\n",
      "\u001b[31my_train.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# We can see the imnported files from Kaggle\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "YS-mnqZr_DlM",
    "outputId": "99d5b9d6-10eb-408a-ec43-dff88f68010b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fashionmnist.zip\n",
      "  inflating: t10k-images-idx3-ubyte  \n",
      "  inflating: fashion-mnist_test.csv  \n",
      "  inflating: train-labels-idx1-ubyte  \n",
      "  inflating: train-images-idx3-ubyte  \n",
      "  inflating: fashion-mnist_train.csv  \n",
      "  inflating: t10k-labels-idx1-ubyte  \n"
     ]
    }
   ],
   "source": [
    "# Now we will unzip the dataset\n",
    "!unzip fashionmnist.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-CROxxO5qpU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "# from TAS_Python_Utilities import data_viz\n",
    "# from TAS_Python_Utilities import data_viz_target\n",
    "# from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0sJZIglK5qpU"
   },
   "source": [
    "To build predictive models in Python we use a set of libraries that are imported here. In particular **pandas** and **sklearn** are particularly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Nl5oaro5qpZ"
   },
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzIh-_gH5qpa"
   },
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQ0MxCJL5qpb"
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzLL29bJ5qpe"
   },
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5rjQDFA5qpf"
   },
   "outputs": [],
   "source": [
    "cv_folds =  5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVEc4h6N5qpi"
   },
   "source": [
    "Set up a dictionary to store simple model perofrmance comparions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzp7DUFG5qpj"
   },
   "outputs": [],
   "source": [
    "model_valid_accuracy_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irqXxXsq5qpo"
   },
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAd5WkPT5qpo"
   },
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "EebI3WEF5qpp",
    "outputId": "ea36c66a-a725-4453-af8b-5a2762ca5805",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.26429</td>\n",
       "      <td>1.5922</td>\n",
       "      <td>-8.7267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63436</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.42684</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>-10.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>-0.50969</td>\n",
       "      <td>1.4689</td>\n",
       "      <td>-10.4410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0    0_0          0                   0       -0.75853       -0.63435   \n",
       "1    0_1          0                   1       -0.75853       -0.63434   \n",
       "2    0_2          0                   2       -0.75853       -0.63435   \n",
       "3    0_3          0                   3       -0.75852       -0.63436   \n",
       "4    0_4          0                   4       -0.75852       -0.63435   \n",
       "\n",
       "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0       -0.10488       -0.10597            0.107650            0.017561   \n",
       "1       -0.10490       -0.10600            0.067851            0.029939   \n",
       "2       -0.10492       -0.10597            0.007275            0.028934   \n",
       "3       -0.10495       -0.10597           -0.013053            0.019448   \n",
       "4       -0.10495       -0.10596            0.005135            0.007652   \n",
       "\n",
       "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0            0.000767               -0.74857                 2.1030   \n",
       "1            0.003385                0.33995                 1.5064   \n",
       "2           -0.005978               -0.26429                 1.5922   \n",
       "3           -0.008974                0.42684                 1.0993   \n",
       "4            0.005245               -0.50969                 1.4689   \n",
       "\n",
       "   linear_acceleration_Z  \n",
       "0                -9.7532  \n",
       "1                -9.4128  \n",
       "2                -8.7267  \n",
       "3               -10.0960  \n",
       "4               -10.4410  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(487680, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dataset = pd.read_csv('X_train.csv')\n",
    "#x_train_dataset = x_train_dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "\n",
    "display(x_train_dataset.head())\n",
    "x_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025773</td>\n",
       "      <td>-0.98864</td>\n",
       "      <td>-0.14801</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>-0.006524</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.027390</td>\n",
       "      <td>0.10043</td>\n",
       "      <td>4.2061</td>\n",
       "      <td>-5.5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025683</td>\n",
       "      <td>-0.98862</td>\n",
       "      <td>-0.14816</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>-0.113960</td>\n",
       "      <td>0.083987</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>-0.70889</td>\n",
       "      <td>3.9905</td>\n",
       "      <td>-8.0273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.98861</td>\n",
       "      <td>-0.14826</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>-0.080518</td>\n",
       "      <td>0.114860</td>\n",
       "      <td>-0.037177</td>\n",
       "      <td>1.45710</td>\n",
       "      <td>2.2828</td>\n",
       "      <td>-11.2990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.025566</td>\n",
       "      <td>-0.98862</td>\n",
       "      <td>-0.14817</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.070067</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>-0.035904</td>\n",
       "      <td>0.71096</td>\n",
       "      <td>1.8582</td>\n",
       "      <td>-12.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.025548</td>\n",
       "      <td>-0.98866</td>\n",
       "      <td>-0.14792</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>-0.029016</td>\n",
       "      <td>-0.015314</td>\n",
       "      <td>3.39960</td>\n",
       "      <td>2.7881</td>\n",
       "      <td>-10.4100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0    0_0          0                   0      -0.025773       -0.98864   \n",
       "1    0_1          0                   1      -0.025683       -0.98862   \n",
       "2    0_2          0                   2      -0.025617       -0.98861   \n",
       "3    0_3          0                   3      -0.025566       -0.98862   \n",
       "4    0_4          0                   4      -0.025548       -0.98866   \n",
       "\n",
       "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0       -0.14801       0.003350           -0.006524           -0.001071   \n",
       "1       -0.14816       0.003439           -0.113960            0.083987   \n",
       "2       -0.14826       0.003571           -0.080518            0.114860   \n",
       "3       -0.14817       0.003609            0.070067            0.033820   \n",
       "4       -0.14792       0.003477            0.152050           -0.029016   \n",
       "\n",
       "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0           -0.027390                0.10043                 4.2061   \n",
       "1           -0.060590               -0.70889                 3.9905   \n",
       "2           -0.037177                1.45710                 2.2828   \n",
       "3           -0.035904                0.71096                 1.8582   \n",
       "4           -0.015314                3.39960                 2.7881   \n",
       "\n",
       "   linear_acceleration_Z  \n",
       "0                -5.5439  \n",
       "1                -8.0273  \n",
       "2               -11.2990  \n",
       "3               -12.2270  \n",
       "4               -10.4100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(488448, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_dataset = pd.read_csv('X_test.csv')\n",
    "#x_train_dataset = x_train_dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "\n",
    "display(x_test_dataset.head())\n",
    "x_test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.374524</td>\n",
       "      <td>-0.358449</td>\n",
       "      <td>-0.378657</td>\n",
       "      <td>-0.332880</td>\n",
       "      <td>-0.008415</td>\n",
       "      <td>-0.019019</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.059338</td>\n",
       "      <td>0.034329</td>\n",
       "      <td>0.029527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.475632</td>\n",
       "      <td>0.084323</td>\n",
       "      <td>0.061624</td>\n",
       "      <td>-0.463890</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>-0.026289</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>-0.003279</td>\n",
       "      <td>-0.041546</td>\n",
       "      <td>-0.015935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.249816</td>\n",
       "      <td>-0.465702</td>\n",
       "      <td>-0.455384</td>\n",
       "      <td>-0.218140</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>-0.028698</td>\n",
       "      <td>0.023899</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>-0.020503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.465803</td>\n",
       "      <td>0.118837</td>\n",
       "      <td>0.085078</td>\n",
       "      <td>-0.449116</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>-0.057254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.441596</td>\n",
       "      <td>0.178490</td>\n",
       "      <td>0.152831</td>\n",
       "      <td>-0.430120</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>-0.062416</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.009886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  orientation_X  orientation_Y  orientation_Z  orientation_W  \\\n",
       "0          0      -0.374524      -0.358449      -0.378657      -0.332880   \n",
       "1          1      -0.475632       0.084323       0.061624      -0.463890   \n",
       "2          2      -0.249816      -0.465702      -0.455384      -0.218140   \n",
       "3          3      -0.465803       0.118837       0.085078      -0.449116   \n",
       "4          4      -0.441596       0.178490       0.152831      -0.430120   \n",
       "\n",
       "   angular_velocity_X  angular_velocity_Y  angular_velocity_Z  \\\n",
       "0           -0.008415           -0.019019            0.013534   \n",
       "1            0.014014           -0.026289            0.012863   \n",
       "2            0.007813           -0.028698            0.023899   \n",
       "3            0.001413           -0.018199            0.013714   \n",
       "4            0.021498            0.061696           -0.062416   \n",
       "\n",
       "   linear_acceleration_X  linear_acceleration_Y  linear_acceleration_Z  \n",
       "0               0.059338               0.034329               0.029527  \n",
       "1              -0.003279              -0.041546              -0.015935  \n",
       "2               0.009038               0.000097              -0.020503  \n",
       "3               0.032076              -0.080281              -0.057254  \n",
       "4              -0.095308               0.033381               0.009886  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3810, 11)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_dataset['series_id'].nunique())\n",
    "\n",
    "test_df = x_train_dataset.groupby(['series_id'])['orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W', \\\n",
    "                                                 'angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z',  \\\n",
    "                                                'linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z'].mean().reset_index()\n",
    "\n",
    "#test_df = test_df.set_index('series_id')\n",
    "test_df_norm = (test_df - test_df.mean()) / (test_df.max() - test_df.min())\n",
    "test_df_norm['series_id'] = test_df['series_id']\n",
    "display(test_df_norm.head())\n",
    "print(test_df_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.029214</td>\n",
       "      <td>-0.560780</td>\n",
       "      <td>-0.544746</td>\n",
       "      <td>-0.002856</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>-0.016565</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>-0.006875</td>\n",
       "      <td>0.029214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.487327</td>\n",
       "      <td>0.105968</td>\n",
       "      <td>0.080633</td>\n",
       "      <td>-0.472482</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.042447</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.011910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.132501</td>\n",
       "      <td>0.425046</td>\n",
       "      <td>0.410354</td>\n",
       "      <td>-0.151260</td>\n",
       "      <td>-0.017816</td>\n",
       "      <td>-0.006887</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>-0.081689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.067046</td>\n",
       "      <td>0.432045</td>\n",
       "      <td>0.416275</td>\n",
       "      <td>0.045858</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>-0.030737</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>0.016182</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.144333</td>\n",
       "      <td>0.422146</td>\n",
       "      <td>0.403773</td>\n",
       "      <td>-0.156713</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>0.083831</td>\n",
       "      <td>-0.080910</td>\n",
       "      <td>-0.026421</td>\n",
       "      <td>-0.037434</td>\n",
       "      <td>-0.030977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  orientation_X  orientation_Y  orientation_Z  orientation_W  \\\n",
       "0          0      -0.029214      -0.560780      -0.544746      -0.002856   \n",
       "1          1      -0.487327       0.105968       0.080633      -0.472482   \n",
       "2          2      -0.132501       0.425046       0.410354      -0.151260   \n",
       "3          3       0.067046       0.432045       0.416275       0.045858   \n",
       "4          4      -0.144333       0.422146       0.403773      -0.156713   \n",
       "\n",
       "   angular_velocity_X  angular_velocity_Y  angular_velocity_Z  \\\n",
       "0            0.002721           -0.016565            0.015286   \n",
       "1            0.046778            0.001434           -0.000368   \n",
       "2           -0.017816           -0.006887            0.004381   \n",
       "3            0.017516           -0.030737            0.028779   \n",
       "4            0.022369            0.083831           -0.080910   \n",
       "\n",
       "   linear_acceleration_X  linear_acceleration_Y  linear_acceleration_Z  \n",
       "0               0.006670              -0.006875               0.029214  \n",
       "1              -0.042447               0.003718               0.011910  \n",
       "2               0.040207               0.004256              -0.081689  \n",
       "3               0.016182               0.013839               0.001728  \n",
       "4              -0.026421              -0.037434              -0.030977  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3816, 11)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_dataset['series_id'].nunique())\n",
    "\n",
    "test_df2 = x_test_dataset.groupby(['series_id'])['orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W', \\\n",
    "                                                 'angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z',  \\\n",
    "                                                'linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z'].mean().reset_index()\n",
    "\n",
    "#test_df = test_df.set_index('series_id')\n",
    "test_df_norm2 = (test_df2 - test_df2.mean()) / (test_df2.max() - test_df2.min())\n",
    "test_df_norm2['series_id'] = test_df2['series_id']\n",
    "display(test_df_norm2.head())\n",
    "print(test_df_norm2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQv7lV9C5qpt"
   },
   "source": [
    "Examine the distribution of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz2AOAnr5qpt",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface\n",
       "0          0        13  fine_concrete\n",
       "1          1        31       concrete\n",
       "2          2        20       concrete\n",
       "3          3        31       concrete\n",
       "4          4        22     soft_tiles"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3810, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 9\n",
    "classes = {0: \"fine_concrete\", 1:\"concrete\", 2: \"soft_tiles\", 3:\"tiled\", 4:\"soft_pvc\", 5:\"hard_tiles_large_space\", 6:\"carpet\", 7:\"hard_tiles\", 8:\"wood\"}\n",
    "\n",
    "y_train_dataset  = pd.read_csv('y_train.csv')\n",
    "display(y_train_dataset.head())\n",
    "\n",
    "#series_ids = list(set(x_train_dataset['series_id']))\n",
    "#print(series_ids)\n",
    "\n",
    "#y_train_dataset = y_train_load\n",
    "#y_train_dataset = y_train_dataset[y_train_load['series_id'].isin(series_ids)]\n",
    "y_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnoPwpxb5qpw",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.531667</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.210167</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.747000</td>\n",
       "      <td>2.105000</td>\n",
       "      <td>5.763167</td>\n",
       "      <td>...</td>\n",
       "      <td>34.515333</td>\n",
       "      <td>23.129500</td>\n",
       "      <td>16.904333</td>\n",
       "      <td>17.842833</td>\n",
       "      <td>21.945000</td>\n",
       "      <td>17.133833</td>\n",
       "      <td>8.332167</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.076500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.895179</td>\n",
       "      <td>0.054768</td>\n",
       "      <td>0.190572</td>\n",
       "      <td>0.251946</td>\n",
       "      <td>0.980251</td>\n",
       "      <td>3.314236</td>\n",
       "      <td>4.967643</td>\n",
       "      <td>7.581242</td>\n",
       "      <td>13.801065</td>\n",
       "      <td>24.201791</td>\n",
       "      <td>...</td>\n",
       "      <td>57.362158</td>\n",
       "      <td>48.845642</td>\n",
       "      <td>42.437083</td>\n",
       "      <td>44.097826</td>\n",
       "      <td>50.863266</td>\n",
       "      <td>44.665644</td>\n",
       "      <td>29.833893</td>\n",
       "      <td>16.919789</td>\n",
       "      <td>9.666896</td>\n",
       "      <td>2.463262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      4.531667     0.001000     0.004667     0.019167     0.051000   \n",
       "std       2.895179     0.054768     0.190572     0.251946     0.980251   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       5.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000     4.000000    14.000000    14.000000    68.000000   \n",
       "\n",
       "            pixel5       pixel6       pixel7       pixel8       pixel9  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      0.210167     0.357500     0.747000     2.105000     5.763167   \n",
       "std       3.314236     4.967643     7.581242    13.801065    24.201791   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     110.000000   156.000000   185.000000   215.000000   237.000000   \n",
       "\n",
       "          ...          pixel775     pixel776     pixel777     pixel778  \\\n",
       "count     ...       6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      ...         34.515333    23.129500    16.904333    17.842833   \n",
       "std       ...         57.362158    48.845642    42.437083    44.097826   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...         58.000000     7.000000     0.000000     0.000000   \n",
       "max       ...        255.000000   255.000000   246.000000   255.000000   \n",
       "\n",
       "          pixel779     pixel780     pixel781     pixel782     pixel783  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean     21.945000    17.133833     8.332167     2.633333     0.845500   \n",
       "std      50.863266    44.665644    29.833893    16.919789     9.666896   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     255.000000   255.000000   252.000000   238.000000   255.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  6000.000000  \n",
       "mean      0.076500  \n",
       "std       2.463262  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max     155.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())\n",
    "if(dataset.select_dtypes(include=[np.object]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.object]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Wy_ZGv15qpz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "row_id                   0\n",
      "series_id                0\n",
      "measurement_number       0\n",
      "orientation_X            0\n",
      "orientation_Y            0\n",
      "orientation_Z            0\n",
      "orientation_W            0\n",
      "angular_velocity_X       0\n",
      "angular_velocity_Y       0\n",
      "angular_velocity_Z       0\n",
      "linear_acceleration_X    0\n",
      "linear_acceleration_Y    0\n",
      "linear_acceleration_Z    0\n",
      "dtype: int64\n",
      "series_id    0\n",
      "group_id     0\n",
      "surface      0\n",
      "dtype: int64\n",
      "row_id                   0\n",
      "series_id                0\n",
      "measurement_number       0\n",
      "orientation_X            0\n",
      "orientation_Y            0\n",
      "orientation_Z            0\n",
      "orientation_W            0\n",
      "angular_velocity_X       0\n",
      "angular_velocity_Y       0\n",
      "angular_velocity_Z       0\n",
      "linear_acceleration_X    0\n",
      "linear_acceleration_Y    0\n",
      "linear_acceleration_Z    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(x_train_dataset.isnull().sum())\n",
    "print(y_train_dataset.isnull().sum())\n",
    "\n",
    "print(x_test_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXr5zoVd5qp3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise fields\n",
    "#data_viz(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "853gf7NJ5qp6"
   },
   "outputs": [],
   "source": [
    "# Visualise fields in relation to target\n",
    "#data_viz_target(dataset, \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBUYSqik5qp-"
   },
   "source": [
    "Isolate the descriptive features we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "we83SCOy5qp_",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.374524</td>\n",
       "      <td>-0.358449</td>\n",
       "      <td>-0.378657</td>\n",
       "      <td>-0.332880</td>\n",
       "      <td>-0.008415</td>\n",
       "      <td>-0.019019</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.059338</td>\n",
       "      <td>0.034329</td>\n",
       "      <td>0.029527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.475632</td>\n",
       "      <td>0.084323</td>\n",
       "      <td>0.061624</td>\n",
       "      <td>-0.463890</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>-0.026289</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>-0.003279</td>\n",
       "      <td>-0.041546</td>\n",
       "      <td>-0.015935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.249816</td>\n",
       "      <td>-0.465702</td>\n",
       "      <td>-0.455384</td>\n",
       "      <td>-0.218140</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>-0.028698</td>\n",
       "      <td>0.023899</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>-0.020503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.465803</td>\n",
       "      <td>0.118837</td>\n",
       "      <td>0.085078</td>\n",
       "      <td>-0.449116</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>-0.080281</td>\n",
       "      <td>-0.057254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.441596</td>\n",
       "      <td>0.178490</td>\n",
       "      <td>0.152831</td>\n",
       "      <td>-0.430120</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>-0.062416</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.009886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.244129</td>\n",
       "      <td>-0.479010</td>\n",
       "      <td>-0.448621</td>\n",
       "      <td>0.275650</td>\n",
       "      <td>-0.023880</td>\n",
       "      <td>-0.013839</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>-0.008568</td>\n",
       "      <td>-0.076409</td>\n",
       "      <td>0.052851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.194341</td>\n",
       "      <td>-0.494502</td>\n",
       "      <td>-0.491252</td>\n",
       "      <td>-0.155780</td>\n",
       "      <td>0.032418</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>-0.016097</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>-0.086384</td>\n",
       "      <td>-0.066448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.459097</td>\n",
       "      <td>0.137802</td>\n",
       "      <td>0.109548</td>\n",
       "      <td>-0.442251</td>\n",
       "      <td>0.028508</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.140569</td>\n",
       "      <td>-0.101145</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015217</td>\n",
       "      <td>-0.537866</td>\n",
       "      <td>-0.513921</td>\n",
       "      <td>0.043603</td>\n",
       "      <td>-0.017343</td>\n",
       "      <td>-0.045504</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>-0.064164</td>\n",
       "      <td>-0.147830</td>\n",
       "      <td>-0.098506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.408188</td>\n",
       "      <td>-0.338355</td>\n",
       "      <td>-0.307171</td>\n",
       "      <td>0.421104</td>\n",
       "      <td>-0.024488</td>\n",
       "      <td>-0.382729</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.187956</td>\n",
       "      <td>0.173938</td>\n",
       "      <td>0.093454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.438407</td>\n",
       "      <td>-0.294717</td>\n",
       "      <td>-0.270778</td>\n",
       "      <td>0.425167</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.027546</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>-0.010507</td>\n",
       "      <td>-0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.259417</td>\n",
       "      <td>-0.470706</td>\n",
       "      <td>-0.430625</td>\n",
       "      <td>0.290241</td>\n",
       "      <td>0.030260</td>\n",
       "      <td>0.050045</td>\n",
       "      <td>-0.045298</td>\n",
       "      <td>-0.038689</td>\n",
       "      <td>-0.014052</td>\n",
       "      <td>0.030352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.178073</td>\n",
       "      <td>0.432531</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.150223</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>-0.056051</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>-0.032914</td>\n",
       "      <td>-0.033506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.198426</td>\n",
       "      <td>0.424503</td>\n",
       "      <td>0.419623</td>\n",
       "      <td>0.174830</td>\n",
       "      <td>-0.002026</td>\n",
       "      <td>0.050517</td>\n",
       "      <td>-0.034228</td>\n",
       "      <td>-0.056453</td>\n",
       "      <td>-0.053588</td>\n",
       "      <td>0.035878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.245822</td>\n",
       "      <td>-0.467604</td>\n",
       "      <td>-0.470592</td>\n",
       "      <td>-0.226945</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>-0.017302</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.004809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.467258</td>\n",
       "      <td>0.114494</td>\n",
       "      <td>0.078319</td>\n",
       "      <td>-0.449164</td>\n",
       "      <td>0.043492</td>\n",
       "      <td>-0.016680</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>-0.076658</td>\n",
       "      <td>0.101954</td>\n",
       "      <td>0.057064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.476123</td>\n",
       "      <td>0.082165</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>-0.467502</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>-0.273740</td>\n",
       "      <td>0.237156</td>\n",
       "      <td>-0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.231713</td>\n",
       "      <td>-0.485561</td>\n",
       "      <td>-0.456985</td>\n",
       "      <td>0.249599</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>-0.039991</td>\n",
       "      <td>0.039019</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>-0.004290</td>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.136874</td>\n",
       "      <td>-0.516202</td>\n",
       "      <td>-0.497494</td>\n",
       "      <td>-0.103477</td>\n",
       "      <td>0.092337</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>-0.035720</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.025588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.428331</td>\n",
       "      <td>-0.310329</td>\n",
       "      <td>-0.283484</td>\n",
       "      <td>0.430913</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.083477</td>\n",
       "      <td>-0.074156</td>\n",
       "      <td>-0.082082</td>\n",
       "      <td>0.085809</td>\n",
       "      <td>0.012723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.470872</td>\n",
       "      <td>-0.229711</td>\n",
       "      <td>-0.201806</td>\n",
       "      <td>0.468419</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>-0.079109</td>\n",
       "      <td>0.069858</td>\n",
       "      <td>0.089410</td>\n",
       "      <td>-0.005559</td>\n",
       "      <td>0.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.015861</td>\n",
       "      <td>-0.537907</td>\n",
       "      <td>-0.511624</td>\n",
       "      <td>0.047245</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.008715</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>-0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.477372</td>\n",
       "      <td>0.077391</td>\n",
       "      <td>0.057224</td>\n",
       "      <td>-0.463016</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.010355</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.134427</td>\n",
       "      <td>-0.516712</td>\n",
       "      <td>-0.504478</td>\n",
       "      <td>-0.114384</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>-0.013210</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>-0.011055</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>-0.032243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.491486</td>\n",
       "      <td>-0.169522</td>\n",
       "      <td>-0.147986</td>\n",
       "      <td>0.485217</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>-0.035927</td>\n",
       "      <td>0.037435</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>0.026288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.183882</td>\n",
       "      <td>0.430309</td>\n",
       "      <td>0.419527</td>\n",
       "      <td>0.159767</td>\n",
       "      <td>-0.006700</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>-0.048802</td>\n",
       "      <td>-0.008966</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>0.018636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.405108</td>\n",
       "      <td>-0.318348</td>\n",
       "      <td>-0.323289</td>\n",
       "      <td>-0.364319</td>\n",
       "      <td>-0.009005</td>\n",
       "      <td>-0.079824</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>0.025450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.330972</td>\n",
       "      <td>-0.420528</td>\n",
       "      <td>-0.387159</td>\n",
       "      <td>0.342142</td>\n",
       "      <td>-0.013105</td>\n",
       "      <td>0.118295</td>\n",
       "      <td>-0.115744</td>\n",
       "      <td>-0.074120</td>\n",
       "      <td>-0.040132</td>\n",
       "      <td>-0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.484620</td>\n",
       "      <td>-0.192319</td>\n",
       "      <td>-0.157732</td>\n",
       "      <td>0.485234</td>\n",
       "      <td>-0.014339</td>\n",
       "      <td>-0.021826</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.031697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.015927</td>\n",
       "      <td>-0.537849</td>\n",
       "      <td>-0.514213</td>\n",
       "      <td>0.044957</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-0.006203</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.044358</td>\n",
       "      <td>-0.014752</td>\n",
       "      <td>-0.014419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>-0.240064</td>\n",
       "      <td>0.395633</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>-0.245075</td>\n",
       "      <td>-0.013977</td>\n",
       "      <td>-0.003043</td>\n",
       "      <td>-0.011234</td>\n",
       "      <td>-0.080335</td>\n",
       "      <td>-0.019350</td>\n",
       "      <td>-0.011759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.368643</td>\n",
       "      <td>0.367128</td>\n",
       "      <td>0.281060</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>-0.114127</td>\n",
       "      <td>0.097964</td>\n",
       "      <td>0.237135</td>\n",
       "      <td>-0.015751</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>0.241605</td>\n",
       "      <td>0.404672</td>\n",
       "      <td>0.395570</td>\n",
       "      <td>0.207745</td>\n",
       "      <td>0.014622</td>\n",
       "      <td>-0.019579</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.113994</td>\n",
       "      <td>-0.078158</td>\n",
       "      <td>0.009144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>0.250293</td>\n",
       "      <td>0.399690</td>\n",
       "      <td>0.399129</td>\n",
       "      <td>0.227420</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>-0.013941</td>\n",
       "      <td>0.014785</td>\n",
       "      <td>-0.057842</td>\n",
       "      <td>0.083218</td>\n",
       "      <td>0.034284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>-0.489092</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>-0.484161</td>\n",
       "      <td>-0.015608</td>\n",
       "      <td>-0.025829</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.070104</td>\n",
       "      <td>0.118651</td>\n",
       "      <td>0.068922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>-0.387333</td>\n",
       "      <td>-0.342348</td>\n",
       "      <td>-0.354576</td>\n",
       "      <td>-0.359236</td>\n",
       "      <td>-0.035767</td>\n",
       "      <td>-0.060073</td>\n",
       "      <td>0.066634</td>\n",
       "      <td>0.072897</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>0.041033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>-0.437607</td>\n",
       "      <td>0.187204</td>\n",
       "      <td>0.159064</td>\n",
       "      <td>-0.415020</td>\n",
       "      <td>-0.009671</td>\n",
       "      <td>-0.015012</td>\n",
       "      <td>0.026713</td>\n",
       "      <td>-0.034970</td>\n",
       "      <td>-0.021170</td>\n",
       "      <td>-0.026445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>-0.412824</td>\n",
       "      <td>0.229856</td>\n",
       "      <td>0.205249</td>\n",
       "      <td>-0.414065</td>\n",
       "      <td>-0.008930</td>\n",
       "      <td>-0.018150</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>-0.152219</td>\n",
       "      <td>-0.045903</td>\n",
       "      <td>-0.029568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.344576</td>\n",
       "      <td>-0.411553</td>\n",
       "      <td>-0.297267</td>\n",
       "      <td>0.290143</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>-0.022663</td>\n",
       "      <td>0.020694</td>\n",
       "      <td>-0.083253</td>\n",
       "      <td>-0.064408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>-0.283653</td>\n",
       "      <td>-0.443116</td>\n",
       "      <td>-0.435576</td>\n",
       "      <td>-0.249073</td>\n",
       "      <td>-0.036539</td>\n",
       "      <td>-0.286666</td>\n",
       "      <td>0.288581</td>\n",
       "      <td>0.030347</td>\n",
       "      <td>-0.054829</td>\n",
       "      <td>-0.033567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>0.368380</td>\n",
       "      <td>0.309736</td>\n",
       "      <td>0.306153</td>\n",
       "      <td>0.347101</td>\n",
       "      <td>-0.008698</td>\n",
       "      <td>-0.014760</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.071503</td>\n",
       "      <td>0.031203</td>\n",
       "      <td>-0.098201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>0.415811</td>\n",
       "      <td>-0.328430</td>\n",
       "      <td>-0.308904</td>\n",
       "      <td>0.422739</td>\n",
       "      <td>0.082948</td>\n",
       "      <td>-0.022010</td>\n",
       "      <td>0.027615</td>\n",
       "      <td>-0.044181</td>\n",
       "      <td>-0.204957</td>\n",
       "      <td>-0.012103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>0.332987</td>\n",
       "      <td>-0.421637</td>\n",
       "      <td>-0.309409</td>\n",
       "      <td>0.278144</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>-0.007967</td>\n",
       "      <td>-0.035362</td>\n",
       "      <td>-0.294937</td>\n",
       "      <td>-0.119828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>-0.485034</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>0.016141</td>\n",
       "      <td>-0.467509</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>-0.037461</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-0.152276</td>\n",
       "      <td>-0.164055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0.396091</td>\n",
       "      <td>0.278757</td>\n",
       "      <td>0.275812</td>\n",
       "      <td>0.370539</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>0.091158</td>\n",
       "      <td>-0.088585</td>\n",
       "      <td>-0.118213</td>\n",
       "      <td>0.047407</td>\n",
       "      <td>-0.047283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>-0.167485</td>\n",
       "      <td>0.429950</td>\n",
       "      <td>0.393537</td>\n",
       "      <td>-0.168274</td>\n",
       "      <td>-0.030416</td>\n",
       "      <td>0.026825</td>\n",
       "      <td>-0.016467</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>-0.033038</td>\n",
       "      <td>0.034895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>-0.373381</td>\n",
       "      <td>0.283966</td>\n",
       "      <td>0.251282</td>\n",
       "      <td>-0.371187</td>\n",
       "      <td>-0.011051</td>\n",
       "      <td>-0.128380</td>\n",
       "      <td>0.125872</td>\n",
       "      <td>-0.071721</td>\n",
       "      <td>-0.200791</td>\n",
       "      <td>-0.143127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>-0.049195</td>\n",
       "      <td>0.458202</td>\n",
       "      <td>0.437045</td>\n",
       "      <td>-0.052522</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.311806</td>\n",
       "      <td>-0.321011</td>\n",
       "      <td>-0.021174</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>-0.008522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>-0.236507</td>\n",
       "      <td>0.397816</td>\n",
       "      <td>0.352411</td>\n",
       "      <td>-0.240151</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>-0.006264</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>-0.012717</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.053308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>-0.079182</td>\n",
       "      <td>0.453967</td>\n",
       "      <td>0.430422</td>\n",
       "      <td>-0.097270</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>-0.044273</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>-0.026483</td>\n",
       "      <td>0.021204</td>\n",
       "      <td>-0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>-0.391182</td>\n",
       "      <td>0.261636</td>\n",
       "      <td>0.234202</td>\n",
       "      <td>-0.378205</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.195399</td>\n",
       "      <td>-0.184970</td>\n",
       "      <td>-0.103011</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>0.416702</td>\n",
       "      <td>0.251366</td>\n",
       "      <td>0.257532</td>\n",
       "      <td>0.399893</td>\n",
       "      <td>0.019713</td>\n",
       "      <td>-0.008637</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>0.080347</td>\n",
       "      <td>0.017585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>-0.075739</td>\n",
       "      <td>0.454447</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>-0.096552</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>-0.016064</td>\n",
       "      <td>-0.032268</td>\n",
       "      <td>0.035248</td>\n",
       "      <td>-0.000483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>-0.466650</td>\n",
       "      <td>0.115412</td>\n",
       "      <td>0.081703</td>\n",
       "      <td>-0.452355</td>\n",
       "      <td>-0.031783</td>\n",
       "      <td>-0.315044</td>\n",
       "      <td>0.310357</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>-0.005801</td>\n",
       "      <td>0.002278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>-0.481342</td>\n",
       "      <td>0.059095</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>-0.468693</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>-0.056688</td>\n",
       "      <td>0.049704</td>\n",
       "      <td>0.051235</td>\n",
       "      <td>-0.001519</td>\n",
       "      <td>0.090247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>-0.106568</td>\n",
       "      <td>0.448229</td>\n",
       "      <td>0.424573</td>\n",
       "      <td>-0.125015</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>0.060783</td>\n",
       "      <td>-0.049631</td>\n",
       "      <td>-0.066633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>0.283345</td>\n",
       "      <td>0.379913</td>\n",
       "      <td>0.377053</td>\n",
       "      <td>0.259839</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>-0.008050</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>-0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>-0.201499</td>\n",
       "      <td>0.414684</td>\n",
       "      <td>0.410108</td>\n",
       "      <td>-0.214684</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>-0.161659</td>\n",
       "      <td>-0.084243</td>\n",
       "      <td>0.271995</td>\n",
       "      <td>0.114416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>-0.124670</td>\n",
       "      <td>0.443681</td>\n",
       "      <td>0.416130</td>\n",
       "      <td>-0.135860</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>-0.061502</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>0.039673</td>\n",
       "      <td>0.066393</td>\n",
       "      <td>0.012903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>0.326641</td>\n",
       "      <td>-0.426994</td>\n",
       "      <td>-0.309279</td>\n",
       "      <td>0.272719</td>\n",
       "      <td>-0.013207</td>\n",
       "      <td>-0.012810</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>-0.233293</td>\n",
       "      <td>-0.129987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orientation_X  orientation_Y  orientation_Z  orientation_W  \\\n",
       "0         -0.374524      -0.358449      -0.378657      -0.332880   \n",
       "1         -0.475632       0.084323       0.061624      -0.463890   \n",
       "2         -0.249816      -0.465702      -0.455384      -0.218140   \n",
       "3         -0.465803       0.118837       0.085078      -0.449116   \n",
       "4         -0.441596       0.178490       0.152831      -0.430120   \n",
       "5          0.244129      -0.479010      -0.448621       0.275650   \n",
       "6         -0.194341      -0.494502      -0.491252      -0.155780   \n",
       "7         -0.459097       0.137802       0.109548      -0.442251   \n",
       "8          0.015217      -0.537866      -0.513921       0.043603   \n",
       "9          0.408188      -0.338355      -0.307171       0.421104   \n",
       "10         0.438407      -0.294717      -0.270778       0.425167   \n",
       "11         0.259417      -0.470706      -0.430625       0.290241   \n",
       "12         0.178073       0.432531       0.418657       0.150223   \n",
       "13         0.198426       0.424503       0.419623       0.174830   \n",
       "14        -0.245822      -0.467604      -0.470592      -0.226945   \n",
       "15        -0.467258       0.114494       0.078319      -0.449164   \n",
       "16        -0.476123       0.082165       0.053307      -0.467502   \n",
       "17         0.231713      -0.485561      -0.456985       0.249599   \n",
       "18        -0.136874      -0.516202      -0.497494      -0.103477   \n",
       "19         0.428331      -0.310329      -0.283484       0.430913   \n",
       "20         0.470872      -0.229711      -0.201806       0.468419   \n",
       "21         0.015861      -0.537907      -0.511624       0.047245   \n",
       "22        -0.477372       0.077391       0.057224      -0.463016   \n",
       "23        -0.134427      -0.516712      -0.504478      -0.114384   \n",
       "24         0.491486      -0.169522      -0.147986       0.485217   \n",
       "25         0.183882       0.430309       0.419527       0.159767   \n",
       "26        -0.405108      -0.318348      -0.323289      -0.364319   \n",
       "27         0.330972      -0.420528      -0.387159       0.342142   \n",
       "28         0.484620      -0.192319      -0.157732       0.485234   \n",
       "29         0.015927      -0.537849      -0.514213       0.044957   \n",
       "...             ...            ...            ...            ...   \n",
       "3780      -0.240064       0.395633       0.356389      -0.245075   \n",
       "3781       0.299665       0.368643       0.367128       0.281060   \n",
       "3782       0.241605       0.404672       0.395570       0.207745   \n",
       "3783       0.250293       0.399690       0.399129       0.227420   \n",
       "3784      -0.489092       0.000672      -0.017143      -0.484161   \n",
       "3785      -0.387333      -0.342348      -0.354576      -0.359236   \n",
       "3786      -0.437607       0.187204       0.159064      -0.415020   \n",
       "3787      -0.412824       0.229856       0.205249      -0.414065   \n",
       "3788       0.344576      -0.411553      -0.297267       0.290143   \n",
       "3789      -0.283653      -0.443116      -0.435576      -0.249073   \n",
       "3790       0.368380       0.309736       0.306153       0.347101   \n",
       "3791       0.415811      -0.328430      -0.308904       0.422739   \n",
       "3792       0.332987      -0.421637      -0.309409       0.278144   \n",
       "3793      -0.485034       0.038481       0.016141      -0.467509   \n",
       "3794       0.396091       0.278757       0.275812       0.370539   \n",
       "3795      -0.167485       0.429950       0.393537      -0.168274   \n",
       "3796      -0.373381       0.283966       0.251282      -0.371187   \n",
       "3797      -0.049195       0.458202       0.437045      -0.052522   \n",
       "3798      -0.236507       0.397816       0.352411      -0.240151   \n",
       "3799      -0.079182       0.453967       0.430422      -0.097270   \n",
       "3800      -0.391182       0.261636       0.234202      -0.378205   \n",
       "3801       0.416702       0.251366       0.257532       0.399893   \n",
       "3802      -0.075739       0.454447       0.435866      -0.096552   \n",
       "3803      -0.466650       0.115412       0.081703      -0.452355   \n",
       "3804      -0.481342       0.059095       0.026202      -0.468693   \n",
       "3805      -0.106568       0.448229       0.424573      -0.125015   \n",
       "3806       0.283345       0.379913       0.377053       0.259839   \n",
       "3807      -0.201499       0.414684       0.410108      -0.214684   \n",
       "3808      -0.124670       0.443681       0.416130      -0.135860   \n",
       "3809       0.326641      -0.426994      -0.309279       0.272719   \n",
       "\n",
       "      angular_velocity_X  angular_velocity_Y  angular_velocity_Z  \\\n",
       "0              -0.008415           -0.019019            0.013534   \n",
       "1               0.014014           -0.026289            0.012863   \n",
       "2               0.007813           -0.028698            0.023899   \n",
       "3               0.001413           -0.018199            0.013714   \n",
       "4               0.021498            0.061696           -0.062416   \n",
       "5              -0.023880           -0.013839            0.006233   \n",
       "6               0.032418            0.015334           -0.016097   \n",
       "7               0.028508           -0.013818            0.005600   \n",
       "8              -0.017343           -0.045504            0.037566   \n",
       "9              -0.024488           -0.382729            0.384359   \n",
       "10             -0.000837           -0.027546            0.028817   \n",
       "11              0.030260            0.050045           -0.045298   \n",
       "12              0.006490           -0.056051            0.038337   \n",
       "13             -0.002026            0.050517           -0.034228   \n",
       "14              0.000951           -0.017302            0.012953   \n",
       "15              0.043492           -0.016680            0.001637   \n",
       "16              0.002191            0.004249            0.030422   \n",
       "17              0.004333           -0.039991            0.039019   \n",
       "18              0.092337            0.030001           -0.035720   \n",
       "19              0.012916            0.083477           -0.074156   \n",
       "20             -0.000888           -0.079109            0.069858   \n",
       "21              0.000091           -0.008715            0.009963   \n",
       "22              0.000589           -0.010355            0.009598   \n",
       "23              0.032749           -0.013210            0.021175   \n",
       "24              0.003864           -0.035927            0.037435   \n",
       "25             -0.006700            0.045202           -0.048802   \n",
       "26             -0.009005           -0.079824            0.082285   \n",
       "27             -0.013105            0.118295           -0.115744   \n",
       "28             -0.014339           -0.021826            0.003195   \n",
       "29             -0.000941           -0.006203            0.003960   \n",
       "...                  ...                 ...                 ...   \n",
       "3780           -0.013977           -0.003043           -0.011234   \n",
       "3781           -0.002534           -0.114127            0.097964   \n",
       "3782            0.014622           -0.019579            0.004461   \n",
       "3783            0.025906           -0.013941            0.014785   \n",
       "3784           -0.015608           -0.025829            0.019274   \n",
       "3785           -0.035767           -0.060073            0.066634   \n",
       "3786           -0.009671           -0.015012            0.026713   \n",
       "3787           -0.008930           -0.018150            0.005417   \n",
       "3788           -0.000884            0.026005           -0.022663   \n",
       "3789           -0.036539           -0.286666            0.288581   \n",
       "3790           -0.008698           -0.014760            0.011441   \n",
       "3791            0.082948           -0.022010            0.027615   \n",
       "3792           -0.005679            0.012160           -0.007967   \n",
       "3793            0.017275            0.033801           -0.037461   \n",
       "3794            0.024533            0.091158           -0.088585   \n",
       "3795           -0.030416            0.026825           -0.016467   \n",
       "3796           -0.011051           -0.128380            0.125872   \n",
       "3797            0.009683            0.311806           -0.321011   \n",
       "3798            0.005775           -0.006264            0.017351   \n",
       "3799            0.024573           -0.044273            0.037637   \n",
       "3800            0.020050            0.195399           -0.184970   \n",
       "3801            0.019713           -0.008637            0.006374   \n",
       "3802            0.015737            0.014184           -0.016064   \n",
       "3803           -0.031783           -0.315044            0.310357   \n",
       "3804            0.016287           -0.056688            0.049704   \n",
       "3805            0.007411            0.000231           -0.001071   \n",
       "3806           -0.001996           -0.008050            0.009508   \n",
       "3807            0.100223            0.155894           -0.161659   \n",
       "3808            0.003009           -0.061502            0.054601   \n",
       "3809           -0.013207           -0.012810            0.010858   \n",
       "\n",
       "      linear_acceleration_X  linear_acceleration_Y  linear_acceleration_Z  \n",
       "0                  0.059338               0.034329               0.029527  \n",
       "1                 -0.003279              -0.041546              -0.015935  \n",
       "2                  0.009038               0.000097              -0.020503  \n",
       "3                  0.032076              -0.080281              -0.057254  \n",
       "4                 -0.095308               0.033381               0.009886  \n",
       "5                 -0.008568              -0.076409               0.052851  \n",
       "6                  0.020300              -0.086384              -0.066448  \n",
       "7                  0.140569              -0.101145               0.034230  \n",
       "8                 -0.064164              -0.147830              -0.098506  \n",
       "9                  0.187956               0.173938               0.093454  \n",
       "10                 0.007847              -0.010507              -0.013532  \n",
       "11                -0.038689              -0.014052               0.030352  \n",
       "12                 0.005397              -0.032914              -0.033506  \n",
       "13                -0.056453              -0.053588               0.035878  \n",
       "14                -0.040887               0.000825              -0.004809  \n",
       "15                -0.076658               0.101954               0.057064  \n",
       "16                -0.273740               0.237156              -0.004597  \n",
       "17                 0.006722              -0.004290               0.008874  \n",
       "18                 0.016785               0.010584               0.025588  \n",
       "19                -0.082082               0.085809               0.012723  \n",
       "20                 0.089410              -0.005559               0.002309  \n",
       "21                 0.015822               0.001347              -0.000337  \n",
       "22                 0.009406               0.012588               0.003604  \n",
       "23                -0.011055               0.003982              -0.032243  \n",
       "24                 0.020440               0.044460               0.026288  \n",
       "25                -0.008966               0.031027               0.018636  \n",
       "26                 0.007330               0.035239               0.025450  \n",
       "27                -0.074120              -0.040132              -0.014109  \n",
       "28                 0.037095               0.045803               0.031697  \n",
       "29                 0.044358              -0.014752              -0.014419  \n",
       "...                     ...                    ...                    ...  \n",
       "3780              -0.080335              -0.019350              -0.011759  \n",
       "3781               0.237135              -0.015751               0.028340  \n",
       "3782               0.113994              -0.078158               0.009144  \n",
       "3783              -0.057842               0.083218               0.034284  \n",
       "3784               0.070104               0.118651               0.068922  \n",
       "3785               0.072897               0.065727               0.041033  \n",
       "3786              -0.034970              -0.021170              -0.026445  \n",
       "3787              -0.152219              -0.045903              -0.029568  \n",
       "3788               0.020694              -0.083253              -0.064408  \n",
       "3789               0.030347              -0.054829              -0.033567  \n",
       "3790               0.071503               0.031203              -0.098201  \n",
       "3791              -0.044181              -0.204957              -0.012103  \n",
       "3792              -0.035362              -0.294937              -0.119828  \n",
       "3793               0.000513              -0.152276              -0.164055  \n",
       "3794              -0.118213               0.047407              -0.047283  \n",
       "3795               0.081663              -0.033038               0.034895  \n",
       "3796              -0.071721              -0.200791              -0.143127  \n",
       "3797              -0.021174               0.016346              -0.008522  \n",
       "3798              -0.012717               0.004249               0.053308  \n",
       "3799              -0.026483               0.021204              -0.002851  \n",
       "3800              -0.103011               0.002329               0.001049  \n",
       "3801               0.027055               0.080347               0.017585  \n",
       "3802              -0.032268               0.035248              -0.000483  \n",
       "3803               0.110774              -0.005801               0.002278  \n",
       "3804               0.051235              -0.001519               0.090247  \n",
       "3805               0.060783              -0.049631              -0.066633  \n",
       "3806               0.003183               0.004861              -0.001567  \n",
       "3807              -0.084243               0.271995               0.114416  \n",
       "3808               0.039673               0.066393               0.012903  \n",
       "3809               0.009471              -0.233293              -0.129987  \n",
       "\n",
       "[3810 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['fine_concrete', 'concrete', 'concrete', ..., 'fine_concrete',\n",
       "       'tiled', 'soft_pvc'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = test_df_norm[test_df_norm.columns[1:]]\n",
    "display(X)\n",
    "Y = np.array(y_train_dataset[\"surface\"])\n",
    "display(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.029214</td>\n",
       "      <td>-0.560780</td>\n",
       "      <td>-0.544746</td>\n",
       "      <td>-0.002856</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>-0.016565</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>-0.006875</td>\n",
       "      <td>0.029214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.487327</td>\n",
       "      <td>0.105968</td>\n",
       "      <td>0.080633</td>\n",
       "      <td>-0.472482</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.042447</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.011910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.132501</td>\n",
       "      <td>0.425046</td>\n",
       "      <td>0.410354</td>\n",
       "      <td>-0.151260</td>\n",
       "      <td>-0.017816</td>\n",
       "      <td>-0.006887</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>-0.081689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.067046</td>\n",
       "      <td>0.432045</td>\n",
       "      <td>0.416275</td>\n",
       "      <td>0.045858</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>-0.030737</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>0.016182</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.144333</td>\n",
       "      <td>0.422146</td>\n",
       "      <td>0.403773</td>\n",
       "      <td>-0.156713</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>0.083831</td>\n",
       "      <td>-0.080910</td>\n",
       "      <td>-0.026421</td>\n",
       "      <td>-0.037434</td>\n",
       "      <td>-0.030977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.292840</td>\n",
       "      <td>-0.477252</td>\n",
       "      <td>-0.480854</td>\n",
       "      <td>-0.260339</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>-0.109751</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>-0.317636</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>0.138536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.421084</td>\n",
       "      <td>0.231490</td>\n",
       "      <td>0.216144</td>\n",
       "      <td>-0.426643</td>\n",
       "      <td>0.028238</td>\n",
       "      <td>-0.030527</td>\n",
       "      <td>0.041090</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.034539</td>\n",
       "      <td>0.045282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.337955</td>\n",
       "      <td>0.321763</td>\n",
       "      <td>0.290751</td>\n",
       "      <td>-0.333600</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>0.049677</td>\n",
       "      <td>-0.041286</td>\n",
       "      <td>-0.032459</td>\n",
       "      <td>0.035880</td>\n",
       "      <td>-0.023877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.419260</td>\n",
       "      <td>0.234532</td>\n",
       "      <td>0.204635</td>\n",
       "      <td>-0.415931</td>\n",
       "      <td>0.026473</td>\n",
       "      <td>0.117355</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.072895</td>\n",
       "      <td>-0.091007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.197023</td>\n",
       "      <td>0.390985</td>\n",
       "      <td>0.391821</td>\n",
       "      <td>0.176154</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>-0.089465</td>\n",
       "      <td>0.093383</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>-0.006075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.413245</td>\n",
       "      <td>0.242720</td>\n",
       "      <td>0.224535</td>\n",
       "      <td>-0.399848</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>-0.012151</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>-0.008783</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.460178</td>\n",
       "      <td>-0.212464</td>\n",
       "      <td>-0.185686</td>\n",
       "      <td>0.448997</td>\n",
       "      <td>0.037552</td>\n",
       "      <td>-0.175086</td>\n",
       "      <td>0.159324</td>\n",
       "      <td>0.057686</td>\n",
       "      <td>-0.036488</td>\n",
       "      <td>-0.025974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.366321</td>\n",
       "      <td>0.260202</td>\n",
       "      <td>0.281016</td>\n",
       "      <td>0.350994</td>\n",
       "      <td>-0.015860</td>\n",
       "      <td>-0.087082</td>\n",
       "      <td>0.082782</td>\n",
       "      <td>0.113610</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.433058</td>\n",
       "      <td>0.157949</td>\n",
       "      <td>0.177731</td>\n",
       "      <td>0.410685</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>-0.033828</td>\n",
       "      <td>-0.051313</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>-0.016813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.196382</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.393135</td>\n",
       "      <td>-0.204051</td>\n",
       "      <td>-0.020336</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>0.061179</td>\n",
       "      <td>-0.006569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.428914</td>\n",
       "      <td>0.165472</td>\n",
       "      <td>0.189242</td>\n",
       "      <td>0.416082</td>\n",
       "      <td>-0.030358</td>\n",
       "      <td>-0.233794</td>\n",
       "      <td>0.226315</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.056692</td>\n",
       "      <td>0.084698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.470543</td>\n",
       "      <td>0.147319</td>\n",
       "      <td>0.129489</td>\n",
       "      <td>-0.455633</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>-0.051508</td>\n",
       "      <td>0.049303</td>\n",
       "      <td>0.043584</td>\n",
       "      <td>-0.066412</td>\n",
       "      <td>-0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.209812</td>\n",
       "      <td>0.384858</td>\n",
       "      <td>0.379580</td>\n",
       "      <td>0.193212</td>\n",
       "      <td>-0.002530</td>\n",
       "      <td>-0.024412</td>\n",
       "      <td>0.023234</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>-0.018501</td>\n",
       "      <td>-0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.185548</td>\n",
       "      <td>0.408769</td>\n",
       "      <td>0.399231</td>\n",
       "      <td>-0.207125</td>\n",
       "      <td>-0.040277</td>\n",
       "      <td>-0.275906</td>\n",
       "      <td>0.280030</td>\n",
       "      <td>0.030611</td>\n",
       "      <td>-0.006171</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.483187</td>\n",
       "      <td>-0.079819</td>\n",
       "      <td>-0.057602</td>\n",
       "      <td>0.473433</td>\n",
       "      <td>-0.031628</td>\n",
       "      <td>-0.029074</td>\n",
       "      <td>0.029065</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>-0.030421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.199072</td>\n",
       "      <td>0.390125</td>\n",
       "      <td>0.388271</td>\n",
       "      <td>0.174860</td>\n",
       "      <td>0.019354</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>-0.034904</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>0.049546</td>\n",
       "      <td>0.017977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.461596</td>\n",
       "      <td>0.165921</td>\n",
       "      <td>0.134992</td>\n",
       "      <td>-0.451458</td>\n",
       "      <td>-0.012427</td>\n",
       "      <td>-0.015974</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>0.015151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.414036</td>\n",
       "      <td>0.241509</td>\n",
       "      <td>0.218787</td>\n",
       "      <td>-0.409315</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>-0.061527</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>-0.009991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.371912</td>\n",
       "      <td>0.253722</td>\n",
       "      <td>0.263097</td>\n",
       "      <td>0.356968</td>\n",
       "      <td>-0.011197</td>\n",
       "      <td>-0.041568</td>\n",
       "      <td>0.035666</td>\n",
       "      <td>0.067273</td>\n",
       "      <td>-0.009579</td>\n",
       "      <td>0.133898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.255505</td>\n",
       "      <td>-0.499689</td>\n",
       "      <td>-0.504444</td>\n",
       "      <td>-0.224594</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>-0.037081</td>\n",
       "      <td>0.043177</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.004921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.211227</td>\n",
       "      <td>-0.505956</td>\n",
       "      <td>-0.483572</td>\n",
       "      <td>0.220913</td>\n",
       "      <td>0.043197</td>\n",
       "      <td>0.283444</td>\n",
       "      <td>-0.277477</td>\n",
       "      <td>-0.087842</td>\n",
       "      <td>-0.016482</td>\n",
       "      <td>-0.021779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.237617</td>\n",
       "      <td>-0.491541</td>\n",
       "      <td>-0.472636</td>\n",
       "      <td>0.251671</td>\n",
       "      <td>-0.011374</td>\n",
       "      <td>-0.025734</td>\n",
       "      <td>0.026006</td>\n",
       "      <td>-0.033102</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>-0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.476367</td>\n",
       "      <td>-0.145083</td>\n",
       "      <td>-0.132336</td>\n",
       "      <td>0.470265</td>\n",
       "      <td>-0.018428</td>\n",
       "      <td>-0.072986</td>\n",
       "      <td>0.064486</td>\n",
       "      <td>-0.083218</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.020122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.497198</td>\n",
       "      <td>-0.195179</td>\n",
       "      <td>-0.210563</td>\n",
       "      <td>-0.487581</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.148829</td>\n",
       "      <td>-0.149534</td>\n",
       "      <td>-0.023913</td>\n",
       "      <td>-0.018411</td>\n",
       "      <td>-0.027421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.323841</td>\n",
       "      <td>-0.454859</td>\n",
       "      <td>-0.458428</td>\n",
       "      <td>-0.296439</td>\n",
       "      <td>-0.012572</td>\n",
       "      <td>-0.014444</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.076567</td>\n",
       "      <td>-0.024085</td>\n",
       "      <td>0.182822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>0.417011</td>\n",
       "      <td>-0.309170</td>\n",
       "      <td>-0.287369</td>\n",
       "      <td>0.427654</td>\n",
       "      <td>0.050767</td>\n",
       "      <td>0.319954</td>\n",
       "      <td>-0.313013</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>0.037836</td>\n",
       "      <td>0.037140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>-0.470222</td>\n",
       "      <td>0.148076</td>\n",
       "      <td>0.120057</td>\n",
       "      <td>-0.458519</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>-0.038758</td>\n",
       "      <td>0.033776</td>\n",
       "      <td>-0.136245</td>\n",
       "      <td>-0.003490</td>\n",
       "      <td>-0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.273538</td>\n",
       "      <td>0.346218</td>\n",
       "      <td>0.352547</td>\n",
       "      <td>0.249088</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>-0.014472</td>\n",
       "      <td>-0.008305</td>\n",
       "      <td>-0.236392</td>\n",
       "      <td>-0.055115</td>\n",
       "      <td>-0.022720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>-0.471927</td>\n",
       "      <td>0.144451</td>\n",
       "      <td>0.123651</td>\n",
       "      <td>-0.454738</td>\n",
       "      <td>0.071434</td>\n",
       "      <td>-0.018502</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.038578</td>\n",
       "      <td>0.042343</td>\n",
       "      <td>0.025004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>-0.383048</td>\n",
       "      <td>-0.400232</td>\n",
       "      <td>-0.402302</td>\n",
       "      <td>-0.366625</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>-0.009754</td>\n",
       "      <td>-0.020088</td>\n",
       "      <td>0.069330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>0.244085</td>\n",
       "      <td>0.365792</td>\n",
       "      <td>0.361619</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>-0.029437</td>\n",
       "      <td>-0.094253</td>\n",
       "      <td>0.087620</td>\n",
       "      <td>0.128035</td>\n",
       "      <td>0.047549</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>-0.265936</td>\n",
       "      <td>0.372115</td>\n",
       "      <td>0.343310</td>\n",
       "      <td>-0.273735</td>\n",
       "      <td>0.049721</td>\n",
       "      <td>-0.049551</td>\n",
       "      <td>0.049545</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>-0.014550</td>\n",
       "      <td>0.009577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>-0.326055</td>\n",
       "      <td>-0.453397</td>\n",
       "      <td>-0.456374</td>\n",
       "      <td>-0.276348</td>\n",
       "      <td>-0.042853</td>\n",
       "      <td>-0.186821</td>\n",
       "      <td>0.192545</td>\n",
       "      <td>0.068131</td>\n",
       "      <td>-0.056126</td>\n",
       "      <td>-0.057326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>-0.258834</td>\n",
       "      <td>-0.498122</td>\n",
       "      <td>-0.492429</td>\n",
       "      <td>-0.227144</td>\n",
       "      <td>-0.027185</td>\n",
       "      <td>-0.003825</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>-0.024959</td>\n",
       "      <td>-0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>-0.404550</td>\n",
       "      <td>0.252807</td>\n",
       "      <td>0.240604</td>\n",
       "      <td>-0.416865</td>\n",
       "      <td>-0.084890</td>\n",
       "      <td>-0.177172</td>\n",
       "      <td>0.154558</td>\n",
       "      <td>0.151187</td>\n",
       "      <td>0.102330</td>\n",
       "      <td>0.078889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0.170528</td>\n",
       "      <td>-0.524762</td>\n",
       "      <td>-0.503358</td>\n",
       "      <td>0.181286</td>\n",
       "      <td>-0.013302</td>\n",
       "      <td>-0.062165</td>\n",
       "      <td>0.080254</td>\n",
       "      <td>0.092296</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.110912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>-0.266476</td>\n",
       "      <td>-0.493394</td>\n",
       "      <td>-0.498938</td>\n",
       "      <td>-0.246300</td>\n",
       "      <td>-0.037957</td>\n",
       "      <td>-0.025849</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.042153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>-0.340506</td>\n",
       "      <td>0.319523</td>\n",
       "      <td>0.291646</td>\n",
       "      <td>-0.337234</td>\n",
       "      <td>-0.008074</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.003865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>0.407421</td>\n",
       "      <td>0.203759</td>\n",
       "      <td>0.226447</td>\n",
       "      <td>0.391416</td>\n",
       "      <td>-0.038173</td>\n",
       "      <td>-0.083370</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>-0.008660</td>\n",
       "      <td>0.025844</td>\n",
       "      <td>-0.014709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.263089</td>\n",
       "      <td>0.273757</td>\n",
       "      <td>0.343121</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>0.072389</td>\n",
       "      <td>-0.070745</td>\n",
       "      <td>-0.073016</td>\n",
       "      <td>0.021625</td>\n",
       "      <td>0.026545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>0.176382</td>\n",
       "      <td>0.400217</td>\n",
       "      <td>0.398870</td>\n",
       "      <td>0.153719</td>\n",
       "      <td>-0.029950</td>\n",
       "      <td>-0.062375</td>\n",
       "      <td>0.058693</td>\n",
       "      <td>0.024557</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>0.004026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>-0.441982</td>\n",
       "      <td>-0.322303</td>\n",
       "      <td>-0.347025</td>\n",
       "      <td>-0.415273</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>-0.018771</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.008082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>0.233337</td>\n",
       "      <td>-0.494023</td>\n",
       "      <td>-0.478156</td>\n",
       "      <td>0.243878</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>-0.016483</td>\n",
       "      <td>0.030753</td>\n",
       "      <td>-0.085700</td>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.023791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>-0.269778</td>\n",
       "      <td>-0.491227</td>\n",
       "      <td>-0.506536</td>\n",
       "      <td>-0.250179</td>\n",
       "      <td>0.078706</td>\n",
       "      <td>-0.024224</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>-0.026215</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>-0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>0.244023</td>\n",
       "      <td>0.365760</td>\n",
       "      <td>0.363106</td>\n",
       "      <td>0.227089</td>\n",
       "      <td>-0.031508</td>\n",
       "      <td>-0.010407</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>-0.072037</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.012135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>-0.249208</td>\n",
       "      <td>-0.503137</td>\n",
       "      <td>-0.505940</td>\n",
       "      <td>-0.216061</td>\n",
       "      <td>0.022942</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>0.021504</td>\n",
       "      <td>0.104806</td>\n",
       "      <td>0.040878</td>\n",
       "      <td>0.057539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>0.212231</td>\n",
       "      <td>0.383888</td>\n",
       "      <td>0.374408</td>\n",
       "      <td>0.180020</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>-0.012733</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>-0.021792</td>\n",
       "      <td>-0.019558</td>\n",
       "      <td>-0.037369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>-0.506865</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>-0.499311</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.021518</td>\n",
       "      <td>0.029816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>0.054315</td>\n",
       "      <td>-0.555575</td>\n",
       "      <td>-0.548302</td>\n",
       "      <td>0.090340</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>0.097766</td>\n",
       "      <td>-0.098539</td>\n",
       "      <td>-0.040802</td>\n",
       "      <td>-0.014105</td>\n",
       "      <td>-0.026664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>-0.394584</td>\n",
       "      <td>0.265638</td>\n",
       "      <td>0.232516</td>\n",
       "      <td>-0.394733</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>-0.088208</td>\n",
       "      <td>0.094158</td>\n",
       "      <td>0.037293</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.035457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>0.281503</td>\n",
       "      <td>0.340842</td>\n",
       "      <td>0.336370</td>\n",
       "      <td>0.247945</td>\n",
       "      <td>-0.013350</td>\n",
       "      <td>-0.030274</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>-0.055099</td>\n",
       "      <td>0.008369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>0.061099</td>\n",
       "      <td>0.432882</td>\n",
       "      <td>0.422119</td>\n",
       "      <td>0.041697</td>\n",
       "      <td>-0.025669</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>-0.033002</td>\n",
       "      <td>-0.020843</td>\n",
       "      <td>-0.006128</td>\n",
       "      <td>-0.014259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>0.265247</td>\n",
       "      <td>0.351788</td>\n",
       "      <td>0.359427</td>\n",
       "      <td>0.251711</td>\n",
       "      <td>-0.053377</td>\n",
       "      <td>-0.036825</td>\n",
       "      <td>0.053777</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>-0.059804</td>\n",
       "      <td>-0.053508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>-0.492732</td>\n",
       "      <td>0.089782</td>\n",
       "      <td>0.063376</td>\n",
       "      <td>-0.478116</td>\n",
       "      <td>-0.021057</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.086176</td>\n",
       "      <td>-0.018548</td>\n",
       "      <td>0.043589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>-0.508603</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>-0.010196</td>\n",
       "      <td>-0.494996</td>\n",
       "      <td>-0.043413</td>\n",
       "      <td>-0.268166</td>\n",
       "      <td>0.264022</td>\n",
       "      <td>0.148309</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.022674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3816 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orientation_X  orientation_Y  orientation_Z  orientation_W  \\\n",
       "0         -0.029214      -0.560780      -0.544746      -0.002856   \n",
       "1         -0.487327       0.105968       0.080633      -0.472482   \n",
       "2         -0.132501       0.425046       0.410354      -0.151260   \n",
       "3          0.067046       0.432045       0.416275       0.045858   \n",
       "4         -0.144333       0.422146       0.403773      -0.156713   \n",
       "5         -0.292840      -0.477252      -0.480854      -0.260339   \n",
       "6         -0.421084       0.231490       0.216144      -0.426643   \n",
       "7         -0.337955       0.321763       0.290751      -0.333600   \n",
       "8         -0.419260       0.234532       0.204635      -0.415931   \n",
       "9          0.197023       0.390985       0.391821       0.176154   \n",
       "10        -0.413245       0.242720       0.224535      -0.399848   \n",
       "11         0.460178      -0.212464      -0.185686       0.448997   \n",
       "12         0.366321       0.260202       0.281016       0.350994   \n",
       "13         0.433058       0.157949       0.177731       0.410685   \n",
       "14        -0.196382       0.405100       0.393135      -0.204051   \n",
       "15         0.428914       0.165472       0.189242       0.416082   \n",
       "16        -0.470543       0.147319       0.129489      -0.455633   \n",
       "17         0.209812       0.384858       0.379580       0.193212   \n",
       "18        -0.185548       0.408769       0.399231      -0.207125   \n",
       "19         0.483187      -0.079819      -0.057602       0.473433   \n",
       "20         0.199072       0.390125       0.388271       0.174860   \n",
       "21        -0.461596       0.165921       0.134992      -0.451458   \n",
       "22        -0.414036       0.241509       0.218787      -0.409315   \n",
       "23         0.371912       0.253722       0.263097       0.356968   \n",
       "24        -0.255505      -0.499689      -0.504444      -0.224594   \n",
       "25         0.211227      -0.505956      -0.483572       0.220913   \n",
       "26         0.237617      -0.491541      -0.472636       0.251671   \n",
       "27         0.476367      -0.145083      -0.132336       0.470265   \n",
       "28        -0.497198      -0.195179      -0.210563      -0.487581   \n",
       "29        -0.323841      -0.454859      -0.458428      -0.296439   \n",
       "...             ...            ...            ...            ...   \n",
       "3786       0.417011      -0.309170      -0.287369       0.427654   \n",
       "3787      -0.470222       0.148076       0.120057      -0.458519   \n",
       "3788       0.273538       0.346218       0.352547       0.249088   \n",
       "3789      -0.471927       0.144451       0.123651      -0.454738   \n",
       "3790      -0.383048      -0.400232      -0.402302      -0.366625   \n",
       "3791       0.244085       0.365792       0.361619       0.223305   \n",
       "3792      -0.265936       0.372115       0.343310      -0.273735   \n",
       "3793      -0.326055      -0.453397      -0.456374      -0.276348   \n",
       "3794      -0.258834      -0.498122      -0.492429      -0.227144   \n",
       "3795      -0.404550       0.252807       0.240604      -0.416865   \n",
       "3796       0.170528      -0.524762      -0.503358       0.181286   \n",
       "3797      -0.266476      -0.493394      -0.498938      -0.246300   \n",
       "3798      -0.340506       0.319523       0.291646      -0.337234   \n",
       "3799       0.407421       0.203759       0.226447       0.391416   \n",
       "3800       0.364200       0.263089       0.273757       0.343121   \n",
       "3801       0.176382       0.400217       0.398870       0.153719   \n",
       "3802      -0.441982      -0.322303      -0.347025      -0.415273   \n",
       "3803       0.233337      -0.494023      -0.478156       0.243878   \n",
       "3804      -0.269778      -0.491227      -0.506536      -0.250179   \n",
       "3805       0.244023       0.365760       0.363106       0.227089   \n",
       "3806      -0.249208      -0.503137      -0.505940      -0.216061   \n",
       "3807       0.212231       0.383888       0.374408       0.180020   \n",
       "3808      -0.506865       0.033018       0.005150      -0.499311   \n",
       "3809       0.054315      -0.555575      -0.548302       0.090340   \n",
       "3810      -0.394584       0.265638       0.232516      -0.394733   \n",
       "3811       0.281503       0.340842       0.336370       0.247945   \n",
       "3812       0.061099       0.432882       0.422119       0.041697   \n",
       "3813       0.265247       0.351788       0.359427       0.251711   \n",
       "3814      -0.492732       0.089782       0.063376      -0.478116   \n",
       "3815      -0.508603       0.023286      -0.010196      -0.494996   \n",
       "\n",
       "      angular_velocity_X  angular_velocity_Y  angular_velocity_Z  \\\n",
       "0               0.002721           -0.016565            0.015286   \n",
       "1               0.046778            0.001434           -0.000368   \n",
       "2              -0.017816           -0.006887            0.004381   \n",
       "3               0.017516           -0.030737            0.028779   \n",
       "4               0.022369            0.083831           -0.080910   \n",
       "5               0.050158           -0.109751            0.060417   \n",
       "6               0.028238           -0.030527            0.041090   \n",
       "7              -0.024490            0.049677           -0.041286   \n",
       "8               0.026473            0.117355           -0.116460   \n",
       "9              -0.001146           -0.089465            0.093383   \n",
       "10              0.072276           -0.012151            0.005922   \n",
       "11              0.037552           -0.175086            0.159324   \n",
       "12             -0.015860           -0.087082            0.082782   \n",
       "13              0.006477            0.028403           -0.033828   \n",
       "14             -0.020336           -0.002538           -0.002950   \n",
       "15             -0.030358           -0.233794            0.226315   \n",
       "16             -0.074474           -0.051508            0.049303   \n",
       "17             -0.002530           -0.024412            0.023234   \n",
       "18             -0.040277           -0.275906            0.280030   \n",
       "19             -0.031628           -0.029074            0.029065   \n",
       "20              0.019354            0.035616           -0.034904   \n",
       "21             -0.012427           -0.015974            0.018790   \n",
       "22              0.032353           -0.061527            0.057375   \n",
       "23             -0.011197           -0.041568            0.035666   \n",
       "24              0.004125            0.041198           -0.037081   \n",
       "25              0.043197            0.283444           -0.277477   \n",
       "26             -0.011374           -0.025734            0.026006   \n",
       "27             -0.018428           -0.072986            0.064486   \n",
       "28              0.017790            0.148829           -0.149534   \n",
       "29             -0.012572           -0.014444            0.017045   \n",
       "...                  ...                 ...                 ...   \n",
       "3786            0.050767            0.319954           -0.313013   \n",
       "3787            0.017556           -0.038758            0.033776   \n",
       "3788            0.050758           -0.014472           -0.008305   \n",
       "3789            0.071434           -0.018502            0.006298   \n",
       "3790            0.009207            0.004782           -0.003008   \n",
       "3791           -0.029437           -0.094253            0.087620   \n",
       "3792            0.049721           -0.049551            0.049545   \n",
       "3793           -0.042853           -0.186821            0.192545   \n",
       "3794           -0.027185           -0.003825            0.007914   \n",
       "3795           -0.084890           -0.177172            0.154558   \n",
       "3796           -0.013302           -0.062165            0.080254   \n",
       "3797           -0.037957           -0.025849            0.019607   \n",
       "3798           -0.008074           -0.003339           -0.000553   \n",
       "3799           -0.038173           -0.083370            0.072443   \n",
       "3800            0.017983            0.072389           -0.070745   \n",
       "3801           -0.029950           -0.062375            0.058693   \n",
       "3802           -0.022436            0.014661           -0.018771   \n",
       "3803            0.026496           -0.016483            0.030753   \n",
       "3804            0.078706           -0.024224            0.012272   \n",
       "3805           -0.031508           -0.010407            0.011279   \n",
       "3806            0.022942           -0.027377            0.021504   \n",
       "3807            0.009141           -0.012733            0.009020   \n",
       "3808           -0.006418            0.000442            0.000750   \n",
       "3809           -0.011282            0.097766           -0.098539   \n",
       "3810            0.062686           -0.088208            0.094158   \n",
       "3811           -0.013350           -0.030274            0.032095   \n",
       "3812           -0.025669            0.024398           -0.033002   \n",
       "3813           -0.053377           -0.036825            0.053777   \n",
       "3814           -0.021057            0.028451           -0.023690   \n",
       "3815           -0.043413           -0.268166            0.264022   \n",
       "\n",
       "      linear_acceleration_X  linear_acceleration_Y  linear_acceleration_Z  \n",
       "0                  0.006670              -0.006875               0.029214  \n",
       "1                 -0.042447               0.003718               0.011910  \n",
       "2                  0.040207               0.004256              -0.081689  \n",
       "3                  0.016182               0.013839               0.001728  \n",
       "4                 -0.026421              -0.037434              -0.030977  \n",
       "5                 -0.317636               0.024710               0.138536  \n",
       "6                  0.020214               0.034539               0.045282  \n",
       "7                 -0.032459               0.035880              -0.023877  \n",
       "8                 -0.020643              -0.072895              -0.091007  \n",
       "9                  0.003612               0.003260              -0.006075  \n",
       "10                 0.028788              -0.008783               0.002401  \n",
       "11                 0.057686              -0.036488              -0.025974  \n",
       "12                 0.113610              -0.000718               0.000352  \n",
       "13                -0.051313              -0.011384              -0.016813  \n",
       "14                 0.022152               0.061179              -0.006569  \n",
       "15                 0.162813               0.056692               0.084698  \n",
       "16                 0.043584              -0.066412              -0.003283  \n",
       "17                 0.014948              -0.018501              -0.000785  \n",
       "18                 0.030611              -0.006171               0.002095  \n",
       "19                 0.033468               0.010492              -0.030421  \n",
       "20                -0.018641               0.049546               0.017977  \n",
       "21                 0.028455               0.011056               0.015151  \n",
       "22                 0.026636              -0.000598              -0.009991  \n",
       "23                 0.067273              -0.009579               0.133898  \n",
       "24                 0.043177               0.014676               0.004921  \n",
       "25                -0.087842              -0.016482              -0.021779  \n",
       "26                -0.033102               0.027340              -0.001303  \n",
       "27                -0.083218               0.022061               0.020122  \n",
       "28                -0.023913              -0.018411              -0.027421  \n",
       "29                 0.076567              -0.024085               0.182822  \n",
       "...                     ...                    ...                    ...  \n",
       "3786              -0.116766               0.037836               0.037140  \n",
       "3787              -0.136245              -0.003490              -0.001282  \n",
       "3788              -0.236392              -0.055115              -0.022720  \n",
       "3789              -0.038578               0.042343               0.025004  \n",
       "3790              -0.009754              -0.020088               0.069330  \n",
       "3791               0.128035               0.047549               0.005375  \n",
       "3792               0.008095              -0.014550               0.009577  \n",
       "3793               0.068131              -0.056126              -0.057326  \n",
       "3794               0.028062              -0.024959              -0.021300  \n",
       "3795               0.151187               0.102330               0.078889  \n",
       "3796               0.092296               0.024266               0.110912  \n",
       "3797               0.035650               0.004319               0.042153  \n",
       "3798              -0.015572               0.010055               0.003865  \n",
       "3799              -0.008660               0.025844              -0.014709  \n",
       "3800              -0.073016               0.021625               0.026545  \n",
       "3801               0.024557              -0.001125               0.004026  \n",
       "3802               0.036462              -0.001124              -0.008082  \n",
       "3803              -0.085700               0.044912               0.023791  \n",
       "3804              -0.026215              -0.027170              -0.003127  \n",
       "3805              -0.072037               0.009213               0.012135  \n",
       "3806               0.104806               0.040878               0.057539  \n",
       "3807              -0.021792              -0.019558              -0.037369  \n",
       "3808              -0.000391              -0.021518               0.029816  \n",
       "3809              -0.040802              -0.014105              -0.026664  \n",
       "3810               0.037293               0.014969               0.035457  \n",
       "3811               0.010904              -0.055099               0.008369  \n",
       "3812              -0.020843              -0.006128              -0.014259  \n",
       "3813               0.022781              -0.059804              -0.053508  \n",
       "3814              -0.086176              -0.018548               0.043589  \n",
       "3815               0.148309               0.022373               0.022674  \n",
       "\n",
       "[3816 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = test_df_norm2[test_df_norm2.columns[1:]]\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYKQubDj5qqC"
   },
   "source": [
    "Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LL0mwaB5qqC",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5232 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0980e668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3030 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0af111d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4600 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0995cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5490 ]  Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23193128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2507 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a231930f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4537 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23053588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3377 ]  Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a230c8e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2263 ]  Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0a67b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1964 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0a3e3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a sample of images from the dataset\n",
    "for i in range(0, 9):\n",
    "    i_rand = randint(0, X.shape[0])\n",
    "\n",
    "    print(\"[\", i_rand, \"] \", classes[Y[i_rand]])\n",
    "    two_d = (X.iloc[i_rand].values.reshape(28, 28))\n",
    "    pyplot.imshow(two_d, cmap='gray')\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VFG21vn5qqG"
   },
   "source": [
    "Normalise the data (important for some models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6r8p3EC5qqH"
   },
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KC01QI6x5qqO"
   },
   "source": [
    "Split the data into a **training set**, a **vaidation set**, and a **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWHFkwB_5qqP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "#     = train_test_split(X, Y, random_state=0, \\\n",
    "#                                     train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X, Y, \\\n",
    "                        random_state=0, \\\n",
    "                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vlpy3ynz5qqS"
   },
   "source": [
    "## Building Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ab9Y-sE5qqT"
   },
   "source": [
    "### A Very Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SpIUtdM5qqU"
   },
   "source": [
    "Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6c651Si15qqU",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMG0m0R65qqZ"
   },
   "source": [
    "Visualise the decision tree so we can see what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOL58f5T5qqa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(my_tree, feature_names, fileName='dt_over.png')\n",
    "#Image(filename='dt_over.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7BvBTig5qqc"
   },
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZgjZkLL5qqe"
   },
   "source": [
    "Assess the performance of the decision tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmKvWRSW5qqf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       1.00      1.00      1.00        94\n",
      "              concrete       1.00      1.00      1.00       399\n",
      "         fine_concrete       1.00      1.00      1.00       173\n",
      "            hard_tiles       1.00      1.00      1.00        10\n",
      "hard_tiles_large_space       1.00      1.00      1.00       151\n",
      "              soft_pvc       1.00      1.00      1.00       368\n",
      "            soft_tiles       1.00      1.00      1.00       153\n",
      "                 tiled       1.00      1.00      1.00       253\n",
      "                  wood       1.00      1.00      1.00       304\n",
      "\n",
      "           avg / total       1.00      1.00      1.00      1905\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>94</td>\n",
       "      <td>399</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>151</td>\n",
       "      <td>368</td>\n",
       "      <td>153</td>\n",
       "      <td>253</td>\n",
       "      <td>304</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  hard_tiles  \\\n",
       "True                                                                  \n",
       "carpet                      94         0              0           0   \n",
       "concrete                     0       399              0           0   \n",
       "fine_concrete                0         0            173           0   \n",
       "hard_tiles                   0         0              0          10   \n",
       "hard_tiles_large_space       0         0              0           0   \n",
       "soft_pvc                     0         0              0           0   \n",
       "soft_tiles                   0         0              0           0   \n",
       "tiled                        0         0              0           0   \n",
       "wood                         0         0              0           0   \n",
       "All                         94       399            173          10   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       0         0           0      0   \n",
       "concrete                                     0         0           0      0   \n",
       "fine_concrete                                0         0           0      0   \n",
       "hard_tiles                                   0         0           0      0   \n",
       "hard_tiles_large_space                     151         0           0      0   \n",
       "soft_pvc                                     0       368           0      0   \n",
       "soft_tiles                                   0         0         153      0   \n",
       "tiled                                        0         0           0    253   \n",
       "wood                                         0         0           0      0   \n",
       "All                                        151       368         153    253   \n",
       "\n",
       "Predicted               wood   All  \n",
       "True                                \n",
       "carpet                     0    94  \n",
       "concrete                   0   399  \n",
       "fine_concrete              0   173  \n",
       "hard_tiles                 0    10  \n",
       "hard_tiles_large_space     0   151  \n",
       "soft_pvc                   0   368  \n",
       "soft_tiles                 0   153  \n",
       "tiled                      0   253  \n",
       "wood                     304   304  \n",
       "All                      304  1905  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vdn_zReD5qqh"
   },
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkyAuhH35qqi",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6391076115485564\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.38      0.42      0.40        31\n",
      "              concrete       0.69      0.61      0.65       158\n",
      "         fine_concrete       0.67      0.62      0.64        84\n",
      "            hard_tiles       0.25      0.25      0.25         4\n",
      "hard_tiles_large_space       0.63      0.63      0.63        62\n",
      "              soft_pvc       0.71      0.75      0.73       148\n",
      "            soft_tiles       0.53      0.71      0.60        55\n",
      "                 tiled       0.73      0.74      0.73       103\n",
      "                  wood       0.54      0.50      0.52       117\n",
      "\n",
      "           avg / total       0.64      0.64      0.64       762\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>34</td>\n",
       "      <td>140</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>157</td>\n",
       "      <td>74</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  hard_tiles  \\\n",
       "True                                                                  \n",
       "carpet                      13         4              2           0   \n",
       "concrete                     4        97              3           1   \n",
       "fine_concrete                3         8             52           0   \n",
       "hard_tiles                   0         0              1           1   \n",
       "hard_tiles_large_space       2         6              2           0   \n",
       "soft_pvc                     0         6              3           0   \n",
       "soft_tiles                   0         5              3           0   \n",
       "tiled                        4         2              3           1   \n",
       "wood                         8        12              9           1   \n",
       "All                         34       140             78           4   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       0         2           3      3   \n",
       "concrete                                    11        11           7     11   \n",
       "fine_concrete                                1         6           4      1   \n",
       "hard_tiles                                   0         0           1      0   \n",
       "hard_tiles_large_space                      39         4           1      1   \n",
       "soft_pvc                                     1       111           7      6   \n",
       "soft_tiles                                   1         2          39      4   \n",
       "tiled                                        1        10           5     76   \n",
       "wood                                         8        11           7      2   \n",
       "All                                         62       157          74    104   \n",
       "\n",
       "Predicted               wood  All  \n",
       "True                               \n",
       "carpet                     4   31  \n",
       "concrete                  13  158  \n",
       "fine_concrete              9   84  \n",
       "hard_tiles                 1    4  \n",
       "hard_tiles_large_space     7   62  \n",
       "soft_pvc                  14  148  \n",
       "soft_tiles                 1   55  \n",
       "tiled                      1  103  \n",
       "wood                      59  117  \n",
       "All                      109  762  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ndzvVVe95qql"
   },
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S5rXtOt45qql"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6395450568678915\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.45      0.42      0.44        64\n",
      "              concrete       0.65      0.60      0.63       222\n",
      "         fine_concrete       0.64      0.62      0.63       106\n",
      "            hard_tiles       0.75      0.43      0.55         7\n",
      "hard_tiles_large_space       0.70      0.65      0.68        95\n",
      "              soft_pvc       0.69      0.76      0.73       216\n",
      "            soft_tiles       0.52      0.67      0.59        89\n",
      "                 tiled       0.75      0.68      0.71       158\n",
      "                  wood       0.57      0.58      0.58       186\n",
      "\n",
      "           avg / total       0.64      0.64      0.64      1143\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>60</td>\n",
       "      <td>206</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>236</td>\n",
       "      <td>115</td>\n",
       "      <td>143</td>\n",
       "      <td>188</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  hard_tiles  \\\n",
       "True                                                                  \n",
       "carpet                      27        14              2           0   \n",
       "concrete                     7       134              5           0   \n",
       "fine_concrete                1         9             66           1   \n",
       "hard_tiles                   0         0              0           3   \n",
       "hard_tiles_large_space       3         5              2           0   \n",
       "soft_pvc                     0        13              7           0   \n",
       "soft_tiles                   2         8              5           0   \n",
       "tiled                       10         8              5           0   \n",
       "wood                        10        15             11           0   \n",
       "All                         60       206            103           4   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       1         1           5      4   \n",
       "concrete                                     9        22          17      5   \n",
       "fine_concrete                                3         9           3      3   \n",
       "hard_tiles                                   1         0           0      0   \n",
       "hard_tiles_large_space                      62         9           4      4   \n",
       "soft_pvc                                     3       164           4     10   \n",
       "soft_tiles                                   1         2          60      6   \n",
       "tiled                                        0         7          14    107   \n",
       "wood                                         8        22           8      4   \n",
       "All                                         88       236         115    143   \n",
       "\n",
       "Predicted               wood   All  \n",
       "True                                \n",
       "carpet                    10    64  \n",
       "concrete                  23   222  \n",
       "fine_concrete             11   106  \n",
       "hard_tiles                 3     7  \n",
       "hard_tiles_large_space     6    95  \n",
       "soft_pvc                  15   216  \n",
       "soft_tiles                 5    89  \n",
       "tiled                      7   158  \n",
       "wood                     108   186  \n",
       "All                      188  1143  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KozSDxzg5qqp"
   },
   "source": [
    "### Less Overiftted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nV6tDvg5qqq"
   },
   "source": [
    "Train a decision tree, setting min samples per leaf to a sensible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elzbKVyT5qqs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLaLtq_v5qqw"
   },
   "source": [
    "Visualise the decision tree so we can see what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rv_o26Pj5qqw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualise the decision tree\n",
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(my_tree, feature_names, fileName=\"dt_under.png\")\n",
    "#Image(filename='dt_under.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbbeRb-v5qqy"
   },
   "source": [
    "Assess the performance of the decision tree on the **training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahQL4fXr5qqz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48871391076115483\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.34      0.45      0.39        94\n",
      "              concrete       0.48      0.71      0.58       399\n",
      "         fine_concrete       0.34      0.18      0.24       173\n",
      "            hard_tiles       0.00      0.00      0.00        10\n",
      "hard_tiles_large_space       0.35      0.45      0.39       151\n",
      "              soft_pvc       0.80      0.40      0.54       368\n",
      "            soft_tiles       0.24      0.14      0.18       153\n",
      "                 tiled       0.55      0.76      0.63       253\n",
      "                  wood       0.51      0.47      0.49       304\n",
      "\n",
      "           avg / total       0.51      0.49      0.47      1905\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>5</td>\n",
       "      <td>285</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>149</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>142</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>124</td>\n",
       "      <td>590</td>\n",
       "      <td>90</td>\n",
       "      <td>194</td>\n",
       "      <td>186</td>\n",
       "      <td>92</td>\n",
       "      <td>352</td>\n",
       "      <td>277</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  \\\n",
       "True                                                      \n",
       "carpet                      42        22              0   \n",
       "concrete                     5       285              5   \n",
       "fine_concrete               18        40             31   \n",
       "hard_tiles                   0         1              0   \n",
       "hard_tiles_large_space      31        14              4   \n",
       "soft_pvc                     3        73              8   \n",
       "soft_tiles                  10        66             29   \n",
       "tiled                        3        33              2   \n",
       "wood                        12        56             11   \n",
       "All                        124       590             90   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       0         0           0     25   \n",
       "concrete                                    13        24           7     19   \n",
       "fine_concrete                               11         0          18     27   \n",
       "hard_tiles                                   9         0           0      0   \n",
       "hard_tiles_large_space                      68         0           9      2   \n",
       "soft_pvc                                    41       149          16     48   \n",
       "soft_tiles                                   9         0          22     10   \n",
       "tiled                                        7         1          14    192   \n",
       "wood                                        36        12           6     29   \n",
       "All                                        194       186          92    352   \n",
       "\n",
       "Predicted               wood   All  \n",
       "True                                \n",
       "carpet                     5    94  \n",
       "concrete                  41   399  \n",
       "fine_concrete             28   173  \n",
       "hard_tiles                 0    10  \n",
       "hard_tiles_large_space    23   151  \n",
       "soft_pvc                  30   368  \n",
       "soft_tiles                 7   153  \n",
       "tiled                      1   253  \n",
       "wood                     142   304  \n",
       "All                      277  1905  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdSn6djr5qq1"
   },
   "source": [
    "Assess the performance of the decision tree on the **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjVHTrx65qq1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46062992125984253\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.29      0.48      0.37        31\n",
      "              concrete       0.42      0.62      0.50       158\n",
      "         fine_concrete       0.29      0.15      0.20        84\n",
      "            hard_tiles       0.00      0.00      0.00         4\n",
      "hard_tiles_large_space       0.43      0.48      0.46        62\n",
      "              soft_pvc       0.82      0.51      0.63       148\n",
      "            soft_tiles       0.29      0.20      0.24        55\n",
      "                 tiled       0.52      0.67      0.58       103\n",
      "                  wood       0.38      0.34      0.36       117\n",
      "\n",
      "           avg / total       0.48      0.46      0.45       762\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>51</td>\n",
       "      <td>231</td>\n",
       "      <td>45</td>\n",
       "      <td>69</td>\n",
       "      <td>91</td>\n",
       "      <td>38</td>\n",
       "      <td>133</td>\n",
       "      <td>104</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  \\\n",
       "True                                                      \n",
       "carpet                      15        10              0   \n",
       "concrete                     1        98              4   \n",
       "fine_concrete               10        24             13   \n",
       "hard_tiles                   0         1              0   \n",
       "hard_tiles_large_space      12         6              2   \n",
       "soft_pvc                     0        31              4   \n",
       "soft_tiles                   2        19             16   \n",
       "tiled                        2        18              2   \n",
       "wood                         9        24              4   \n",
       "All                         51       231             45   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       0         0           0      2   \n",
       "concrete                                     8         8           2      7   \n",
       "fine_concrete                                1         0           5     15   \n",
       "hard_tiles                                   3         0           0      0   \n",
       "hard_tiles_large_space                      30         1           3      2   \n",
       "soft_pvc                                     7        75           6     20   \n",
       "soft_tiles                                   1         0          11      4   \n",
       "tiled                                        2         1           8     69   \n",
       "wood                                        17         6           3     14   \n",
       "All                                         69        91          38    133   \n",
       "\n",
       "Predicted               wood  All  \n",
       "True                               \n",
       "carpet                     4   31  \n",
       "concrete                  30  158  \n",
       "fine_concrete             16   84  \n",
       "hard_tiles                 0    4  \n",
       "hard_tiles_large_space     6   62  \n",
       "soft_pvc                   5  148  \n",
       "soft_tiles                 2   55  \n",
       "tiled                      1  103  \n",
       "wood                      40  117  \n",
       "All                      104  762  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBBJWc8t5qq3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4558180227471566\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.29      0.38      0.33        64\n",
      "              concrete       0.46      0.68      0.55       222\n",
      "         fine_concrete       0.23      0.12      0.16       106\n",
      "            hard_tiles       0.00      0.00      0.00         7\n",
      "hard_tiles_large_space       0.35      0.44      0.39        95\n",
      "              soft_pvc       0.79      0.46      0.58       216\n",
      "            soft_tiles       0.19      0.12      0.15        89\n",
      "                 tiled       0.56      0.72      0.63       158\n",
      "                  wood       0.40      0.37      0.38       186\n",
      "\n",
      "           avg / total       0.46      0.46      0.44      1143\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>82</td>\n",
       "      <td>324</td>\n",
       "      <td>56</td>\n",
       "      <td>121</td>\n",
       "      <td>126</td>\n",
       "      <td>59</td>\n",
       "      <td>203</td>\n",
       "      <td>172</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  \\\n",
       "True                                                      \n",
       "carpet                      24        20              0   \n",
       "concrete                     2       150              3   \n",
       "fine_concrete               11        18             13   \n",
       "hard_tiles                   0         0              0   \n",
       "hard_tiles_large_space      24         7              2   \n",
       "soft_pvc                     3        41              3   \n",
       "soft_tiles                   4        35             22   \n",
       "tiled                        6        15              2   \n",
       "wood                         8        38             11   \n",
       "All                         82       324             56   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       0         0           0     12   \n",
       "concrete                                     7         8           5      8   \n",
       "fine_concrete                                9         0          13     20   \n",
       "hard_tiles                                   7         0           0      0   \n",
       "hard_tiles_large_space                      42         0           9      2   \n",
       "soft_pvc                                    18       100           6     26   \n",
       "soft_tiles                                   5         1          11      7   \n",
       "tiled                                        3         3          13    113   \n",
       "wood                                        30        14           2     15   \n",
       "All                                        121       126          59    203   \n",
       "\n",
       "Predicted               wood   All  \n",
       "True                                \n",
       "carpet                     8    64  \n",
       "concrete                  39   222  \n",
       "fine_concrete             22   106  \n",
       "hard_tiles                 0     7  \n",
       "hard_tiles_large_space     9    95  \n",
       "soft_pvc                  19   216  \n",
       "soft_tiles                 4    89  \n",
       "tiled                      3   158  \n",
       "wood                      68   186  \n",
       "All                      172  1143  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brCfjoqe5qq5"
   },
   "source": [
    "## Choosing Parameters Using a Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVQAFe6n5qq6"
   },
   "source": [
    "Use a cross validation to perfrom an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xr6kat855qq7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74823529 0.7464455  0.72921615 0.75       0.73095238 0.72619048\n",
      " 0.74761905 0.73205742 0.73444976 0.76442308]\n"
     ]
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "scores = cross_val_score(my_tree, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kv7Epfc5qq8"
   },
   "source": [
    "An alternative to using post pruning explicitly is to use a grid search through a large set of possible parameters. Here we try depths between 3 and 20 and different limits on the minimum number of samples per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "vSBEuGA05qq-",
    "outputId": "6c61ea39-8b8f-4cf3-b7fd-171f18c2fff4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6902380952380952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.17427051, 0.29040933, 0.29170454, 0.3037529 , 0.27801788,\n",
       "        0.27113903, 0.27169704, 0.26272297, 0.26308298, 0.26486301,\n",
       "        0.2801199 , 0.28788519, 0.29952598, 0.28118944, 0.2838695 ,\n",
       "        0.30352557, 0.2568351 , 0.46159637, 0.44768941, 0.45452452,\n",
       "        0.45159161, 0.44803488, 0.44784856, 0.48169899, 0.48510253,\n",
       "        0.48310244, 0.469733  , 0.46219254, 0.46866906, 0.46726251,\n",
       "        0.46606326, 0.46651292]),\n",
       " 'mean_score_time': array([0.00439465, 0.00368178, 0.00360608, 0.00450003, 0.00284398,\n",
       "        0.00324094, 0.00424194, 0.00274861, 0.00283086, 0.00318491,\n",
       "        0.00329006, 0.00430489, 0.00393355, 0.00527203, 0.00305355,\n",
       "        0.0041759 , 0.00308335, 0.00309956, 0.00376606, 0.00308645,\n",
       "        0.00292432, 0.00291407, 0.00436711, 0.00493491, 0.00388932,\n",
       "        0.00421607, 0.00328803, 0.00309992, 0.004439  , 0.00462842,\n",
       "        0.00329006, 0.00369823]),\n",
       " 'mean_test_score': array([0.45380952, 0.68214286, 0.6802381 , 0.6802381 , 0.6802381 ,\n",
       "        0.6802381 , 0.6802381 , 0.6802381 , 0.6802381 , 0.6802381 ,\n",
       "        0.6802381 , 0.6802381 , 0.6802381 , 0.6802381 , 0.6802381 ,\n",
       "        0.6802381 , 0.50571429, 0.6902381 , 0.6902381 , 0.6902381 ,\n",
       "        0.6902381 , 0.6902381 , 0.6902381 , 0.6902381 , 0.6902381 ,\n",
       "        0.6902381 , 0.6902381 , 0.6902381 , 0.6902381 , 0.6902381 ,\n",
       "        0.6902381 , 0.6902381 ]),\n",
       " 'mean_train_score': array([0.47498222, 0.73499768, 0.73953012, 0.73953012, 0.73953012,\n",
       "        0.73953012, 0.73953012, 0.73953012, 0.73953012, 0.73953012,\n",
       "        0.73953012, 0.73953012, 0.73953012, 0.73953012, 0.73953012,\n",
       "        0.73953012, 0.51881821, 0.73593646, 0.73593646, 0.73593646,\n",
       "        0.73593646, 0.73593646, 0.73593646, 0.73593646, 0.73593646,\n",
       "        0.73593646, 0.73593646, 0.73593646, 0.73593646, 0.73593646,\n",
       "        0.73593646, 0.73593646]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42,\n",
       "                    45, 48, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36,\n",
       "                    39, 42, 45, 48],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}],\n",
       " 'rank_test_score': array([32, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 31,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.45484791, 0.67205323, 0.66825095, 0.66825095, 0.66825095,\n",
       "        0.66825095, 0.66825095, 0.66825095, 0.66825095, 0.66825095,\n",
       "        0.66825095, 0.66825095, 0.66825095, 0.66825095, 0.66825095,\n",
       "        0.66825095, 0.50665399, 0.67347909, 0.67347909, 0.67347909,\n",
       "        0.67347909, 0.67347909, 0.67347909, 0.67347909, 0.67347909,\n",
       "        0.67347909, 0.67347909, 0.67347909, 0.67347909, 0.67347909,\n",
       "        0.67347909, 0.67347909]),\n",
       " 'split0_train_score': array([0.46564885, 0.73377863, 0.74284351, 0.74284351, 0.74284351,\n",
       "        0.74284351, 0.74284351, 0.74284351, 0.74284351, 0.74284351,\n",
       "        0.74284351, 0.74284351, 0.74284351, 0.74284351, 0.74284351,\n",
       "        0.74284351, 0.52337786, 0.72757634, 0.72757634, 0.72757634,\n",
       "        0.72757634, 0.72757634, 0.72757634, 0.72757634, 0.72757634,\n",
       "        0.72757634, 0.72757634, 0.72757634, 0.72757634, 0.72757634,\n",
       "        0.72757634, 0.72757634]),\n",
       " 'split1_test_score': array([0.45276718, 0.69227099, 0.69227099, 0.69227099, 0.69227099,\n",
       "        0.69227099, 0.69227099, 0.69227099, 0.69227099, 0.69227099,\n",
       "        0.69227099, 0.69227099, 0.69227099, 0.69227099, 0.69227099,\n",
       "        0.69227099, 0.50477099, 0.70706107, 0.70706107, 0.70706107,\n",
       "        0.70706107, 0.70706107, 0.70706107, 0.70706107, 0.70706107,\n",
       "        0.70706107, 0.70706107, 0.70706107, 0.70706107, 0.70706107,\n",
       "        0.70706107, 0.70706107]),\n",
       " 'split1_train_score': array([0.48431559, 0.73621673, 0.73621673, 0.73621673, 0.73621673,\n",
       "        0.73621673, 0.73621673, 0.73621673, 0.73621673, 0.73621673,\n",
       "        0.73621673, 0.73621673, 0.73621673, 0.73621673, 0.73621673,\n",
       "        0.73621673, 0.51425856, 0.74429658, 0.74429658, 0.74429658,\n",
       "        0.74429658, 0.74429658, 0.74429658, 0.74429658, 0.74429658,\n",
       "        0.74429658, 0.74429658, 0.74429658, 0.74429658, 0.74429658,\n",
       "        0.74429658, 0.74429658]),\n",
       " 'std_fit_time': array([0.0098964 , 0.0032773 , 0.0155946 , 0.01181793, 0.02193511,\n",
       "        0.00515091, 0.00434494, 0.01612401, 0.01255798, 0.01130605,\n",
       "        0.02436805, 0.00113702, 0.00925517, 0.00683045, 0.01195145,\n",
       "        0.0336355 , 0.00435793, 0.02001941, 0.02968347, 0.01670527,\n",
       "        0.0274123 , 0.02788007, 0.01940751, 0.03284216, 0.02827752,\n",
       "        0.03326523, 0.02278113, 0.0197227 , 0.0297991 , 0.02960944,\n",
       "        0.02851057, 0.02929902]),\n",
       " 'std_score_time': array([2.32577324e-04, 6.23583794e-04, 2.57015228e-04, 1.05297565e-03,\n",
       "        1.31130219e-06, 3.11017036e-04, 8.73088837e-04, 3.54051590e-05,\n",
       "        1.56044960e-04, 3.31044197e-04, 4.93884087e-04, 1.04403496e-03,\n",
       "        3.58700752e-04, 2.53808498e-03, 2.03490257e-04, 2.02894211e-04,\n",
       "        1.46508217e-04, 1.24573708e-04, 7.94172287e-04, 4.94718552e-05,\n",
       "        9.14335251e-05, 1.31726265e-04, 1.27792358e-03, 2.17795372e-04,\n",
       "        1.00255013e-03, 1.51193142e-03, 1.28984451e-04, 1.71661377e-05,\n",
       "        5.97834587e-04, 7.06434250e-04, 2.23040581e-04, 6.30021095e-04]),\n",
       " 'std_test_score': array([0.00104036, 0.01010886, 0.01201   , 0.01201   , 0.01201   ,\n",
       "        0.01201   , 0.01201   , 0.01201   , 0.01201   , 0.01201   ,\n",
       "        0.01201   , 0.01201   , 0.01201   , 0.01201   , 0.01201   ,\n",
       "        0.01201   , 0.0009415 , 0.01679096, 0.01679096, 0.01679096,\n",
       "        0.01679096, 0.01679096, 0.01679096, 0.01679096, 0.01679096,\n",
       "        0.01679096, 0.01679096, 0.01679096, 0.01679096, 0.01679096,\n",
       "        0.01679096, 0.01679096]),\n",
       " 'std_train_score': array([0.00933337, 0.00121905, 0.00331339, 0.00331339, 0.00331339,\n",
       "        0.00331339, 0.00331339, 0.00331339, 0.00331339, 0.00331339,\n",
       "        0.00331339, 0.00331339, 0.00331339, 0.00331339, 0.00331339,\n",
       "        0.00331339, 0.00455965, 0.00836012, 0.00836012, 0.00836012,\n",
       "        0.00836012, 0.00836012, 0.00836012, 0.00836012, 0.00836012,\n",
       "        0.00836012, 0.00836012, 0.00836012, 0.00836012, 0.00836012,\n",
       "        0.00836012, 0.00836012])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWS8-j2U5qrA"
   },
   "source": [
    "Evaluate the performance of the tuned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XULQ0EzK5qrC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7455555555555555\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.71      0.74       192\n",
      "          1       0.98      0.83      0.90       185\n",
      "          2       0.69      0.61      0.65       157\n",
      "          3       0.54      0.89      0.67       188\n",
      "          4       0.57      0.51      0.54       157\n",
      "          5       0.79      0.74      0.76       170\n",
      "          6       0.58      0.45      0.51       173\n",
      "          7       0.81      0.86      0.84       181\n",
      "          8       0.85      0.90      0.88       199\n",
      "          9       0.93      0.86      0.89       198\n",
      "\n",
      "avg / total       0.76      0.75      0.75      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>179</td>\n",
       "      <td>156</td>\n",
       "      <td>140</td>\n",
       "      <td>307</td>\n",
       "      <td>140</td>\n",
       "      <td>158</td>\n",
       "      <td>134</td>\n",
       "      <td>192</td>\n",
       "      <td>212</td>\n",
       "      <td>182</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          137    0    4   33    2    1    2    0   13    0   192\n",
       "1            1  153    6   23    1    1    0    0    0    0   185\n",
       "2            0    0   96    5   39    0   14    0    3    0   157\n",
       "3            8    2    5  167    1    1    1    0    3    0   188\n",
       "4            1    1   11   33   80    0   31    0    0    0   157\n",
       "5            0    0    2   11    0  125    0   25    3    4   170\n",
       "6           32    0   15   26   14    0   78    0    8    0   173\n",
       "7            0    0    0    1    0   16    0  156    0    8   181\n",
       "8            0    0    1    4    3    3    7    1  180    0   199\n",
       "9            0    0    0    4    0   11    1   10    2  170   198\n",
       "All        179  156  140  307  140  158  134  192  212  182  1800"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtZ0H4vP5qrE"
   },
   "source": [
    "Visualise the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHfCO1qQ5qrG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_tree = tree.DecisionTreeClassifier(min_samples_split=200, criterion='gini', max_depth=8)\n",
    "best_tree = best_tree.fit(X_train, y_train)\n",
    "\n",
    "# visualise the decision tree\n",
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(best_tree, feature_names, 'dt_tuned.png')\n",
    "#Image(filename='dt_tuned.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GIPH3wHy5qrI"
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FQnilgY5qrJ"
   },
   "source": [
    "We can easily use the same patterns to train other types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mP0pqaWY5qrK"
   },
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nNePYqtN5qrK"
   },
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYiw3Q3w5qrL",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.RandomForestClassifier(n_estimators=300, \\\n",
    "                                           max_features = 3,\\\n",
    "                                           min_samples_split=200)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wBOdRxP5qrP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7608333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.84      0.78       128\n",
      "          1       0.87      0.92      0.89       120\n",
      "          2       0.56      0.75      0.64       100\n",
      "          3       0.69      0.82      0.75       117\n",
      "          4       0.64      0.60      0.62       139\n",
      "          5       0.92      0.79      0.85       111\n",
      "          6       0.64      0.23      0.33       124\n",
      "          7       0.82      0.83      0.82       119\n",
      "          8       0.91      0.93      0.92       124\n",
      "          9       0.82      0.94      0.88       118\n",
      "\n",
      "avg / total       0.76      0.76      0.75      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>149</td>\n",
       "      <td>126</td>\n",
       "      <td>133</td>\n",
       "      <td>139</td>\n",
       "      <td>130</td>\n",
       "      <td>96</td>\n",
       "      <td>44</td>\n",
       "      <td>121</td>\n",
       "      <td>127</td>\n",
       "      <td>135</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4   5   6    7    8    9   All\n",
       "True                                                           \n",
       "0          108    0    2    8    2   0   5    0    3    0   128\n",
       "1            2  110    5    3    0   0   0    0    0    0   120\n",
       "2            3    0   75    0   18   0   3    0    1    0   100\n",
       "3            2   12    3   96    1   0   3    0    0    0   117\n",
       "4            1    3   24   21   83   0   5    0    2    0   139\n",
       "5            0    0    0    0    0  88   0   14    0    9   111\n",
       "6           33    1   23    9   25   0  28    0    5    0   124\n",
       "7            0    0    0    0    0   5   0   99    0   15   119\n",
       "8            0    0    1    2    1   3   0    2  115    0   124\n",
       "9            0    0    0    0    0   0   0    6    1  111   118\n",
       "All        149  126  133  139  130  96  44  121  127  135  1200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsJsuSjx5qrS"
   },
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3i93dZ-5qrT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   0.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   0.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   0.6s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   0.6s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   1.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   1.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   1.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 8, 'min_samples_split': 200, 'n_estimators': 350}\n",
      "0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [200] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Random Forest\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SH84LO_o5qrV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7911111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.81      0.78       192\n",
      "          1       0.99      0.87      0.93       185\n",
      "          2       0.69      0.73      0.71       157\n",
      "          3       0.66      0.86      0.74       188\n",
      "          4       0.56      0.63      0.59       157\n",
      "          5       0.90      0.86      0.88       170\n",
      "          6       0.70      0.33      0.45       173\n",
      "          7       0.88      0.83      0.86       181\n",
      "          8       0.90      0.94      0.92       199\n",
      "          9       0.89      0.95      0.92       198\n",
      "\n",
      "avg / total       0.80      0.79      0.78      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>162</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>207</td>\n",
       "      <td>163</td>\n",
       "      <td>167</td>\n",
       "      <td>247</td>\n",
       "      <td>178</td>\n",
       "      <td>163</td>\n",
       "      <td>81</td>\n",
       "      <td>172</td>\n",
       "      <td>209</td>\n",
       "      <td>213</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          155    0    5   21    1    0   0    0   10    0   192\n",
       "1            1  161    4   15    4    0   0    0    0    0   185\n",
       "2            2    0  115    1   29    0   7    0    3    0   157\n",
       "3            8    2    3  162    9    0   4    0    0    0   188\n",
       "4            0    0   20   27   99    0  10    0    1    0   157\n",
       "5            0    0    0    0    0  147   0   16    2    5   170\n",
       "6           41    0   18   18   36    0  57    0    3    0   173\n",
       "7            0    0    0    0    0   12   0  151    0   18   181\n",
       "8            0    0    2    3    0    2   3    0  188    1   199\n",
       "9            0    0    0    0    0    2   0    5    2  189   198\n",
       "All        207  163  167  247  178  163  81  172  209  213  1800"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlEAzMYw5qrW"
   },
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9VZrWup5qrW"
   },
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyP_uWXq5qrX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 50), \\\n",
    "                                      n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1I8i00O5qrZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7533333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.84      0.78       128\n",
      "          1       0.92      0.88      0.90       120\n",
      "          2       0.56      0.64      0.60       100\n",
      "          3       0.69      0.74      0.71       117\n",
      "          4       0.68      0.70      0.69       139\n",
      "          5       0.71      0.86      0.78       111\n",
      "          6       0.65      0.33      0.44       124\n",
      "          7       0.86      0.80      0.83       119\n",
      "          8       0.85      0.81      0.83       124\n",
      "          9       0.86      0.93      0.89       118\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>149</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "      <td>125</td>\n",
       "      <td>142</td>\n",
       "      <td>135</td>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>119</td>\n",
       "      <td>128</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          108    0    3    8    3    0   2    0    4    0   128\n",
       "1            1  106    5    5    0    3   0    0    0    0   120\n",
       "2            2    0   64    0   25    0   7    0    2    0   100\n",
       "3            4    6    3   86    1   15   2    0    0    0   117\n",
       "4            1    1   12   14   97    1   9    0    4    0   139\n",
       "5            1    0    0    0    0   96   0    9    2    3   111\n",
       "6           30    2   19   11   14    1  41    0    6    0   124\n",
       "7            0    0    0    0    0    9   0   95    0   15   119\n",
       "8            2    0    8    1    2    8   2    0  101    0   124\n",
       "9            0    0    0    0    0    2   0    6    0  110   118\n",
       "All        149  115  114  125  142  135  63  110  119  128  1200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlSA_9-X5qrb"
   },
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGkDZuko5qrc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50, total=   5.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50, total=   5.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100, total=  10.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100, total=  11.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150, total=  16.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150, total=  17.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200, total=  23.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200, total=  24.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250, total=  27.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250, total=  30.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300, total=  35.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300, total=  34.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350, total=  39.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350 \n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBacMcps5qrd"
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1tE9e_vn5qrf"
   },
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQMVuJXc5qrf"
   },
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aekF89-5qrg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=200, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 200), \\\n",
    "                                       n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy_eVc5m5qrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2809917355371901\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.24      0.13      0.17        62\n",
      "              concrete       0.29      0.22      0.25       212\n",
      "         fine_concrete       0.20      0.28      0.23        99\n",
      "            hard_tiles       0.50      0.14      0.22         7\n",
      "hard_tiles_large_space       0.19      0.20      0.19        90\n",
      "              soft_pvc       0.32      0.44      0.37       209\n",
      "            soft_tiles       0.29      0.30      0.29        81\n",
      "                 tiled       0.29      0.26      0.27       149\n",
      "                  wood       0.32      0.27      0.29       180\n",
      "\n",
      "           avg / total       0.28      0.28      0.28      1089\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>34</td>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>288</td>\n",
       "      <td>84</td>\n",
       "      <td>136</td>\n",
       "      <td>149</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  hard_tiles  \\\n",
       "True                                                                  \n",
       "carpet                       8        10              8           0   \n",
       "concrete                     6        47             27           0   \n",
       "fine_concrete                1        12             28           1   \n",
       "hard_tiles                   0         0              0           1   \n",
       "hard_tiles_large_space       0         7             11           0   \n",
       "soft_pvc                     1        24             24           0   \n",
       "soft_tiles                   1         8              3           0   \n",
       "tiled                        3        31             16           0   \n",
       "wood                        14        21             23           0   \n",
       "All                         34       160            140           2   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       3         9           3     10   \n",
       "concrete                                    21        52          21     19   \n",
       "fine_concrete                                8        30           7      3   \n",
       "hard_tiles                                   3         0           1      0   \n",
       "hard_tiles_large_space                      18        20           7      9   \n",
       "soft_pvc                                    13        93           5     29   \n",
       "soft_tiles                                  13        12          24      9   \n",
       "tiled                                        8        33           8     39   \n",
       "wood                                         9        39           8     18   \n",
       "All                                         96       288          84    136   \n",
       "\n",
       "Predicted               wood   All  \n",
       "True                                \n",
       "carpet                    11    62  \n",
       "concrete                  19   212  \n",
       "fine_concrete              9    99  \n",
       "hard_tiles                 2     7  \n",
       "hard_tiles_large_space    18    90  \n",
       "soft_pvc                  20   209  \n",
       "soft_tiles                11    81  \n",
       "tiled                     11   149  \n",
       "wood                      48   180  \n",
       "All                      149  1089  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "#model_valid_accuracy_comparisons[\"AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5enkZBb55qrl"
   },
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVYXOSM_5qrl"
   },
   "outputs": [],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    " 'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned AdaBoost\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUSU0Dj_5qrq"
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BV6sNLX25qrs"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4YrQQTf5qrs"
   },
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Alj3eI0p5qrt",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with logistic regression\n",
    "my_model = linear_model.LogisticRegression()\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d17vr0E05qrv",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3002754820936639\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.00      0.00      0.00        62\n",
      "              concrete       0.26      0.63      0.37       212\n",
      "         fine_concrete       0.00      0.00      0.00        99\n",
      "            hard_tiles       0.00      0.00      0.00         7\n",
      "hard_tiles_large_space       0.00      0.00      0.00        90\n",
      "              soft_pvc       0.30      0.61      0.40       209\n",
      "            soft_tiles       0.00      0.00      0.00        81\n",
      "                 tiled       0.00      0.00      0.00       149\n",
      "                  wood       0.47      0.36      0.41       180\n",
      "\n",
      "           avg / total       0.19      0.30      0.22      1089\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>concrete</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>134</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>94</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>521</td>\n",
       "      <td>430</td>\n",
       "      <td>138</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               concrete  soft_pvc  wood   All\n",
       "True                                                  \n",
       "carpet                        45        14     3    62\n",
       "concrete                     134        70     8   212\n",
       "fine_concrete                 52        31    16    99\n",
       "hard_tiles                     0         6     1     7\n",
       "hard_tiles_large_space        31        54     5    90\n",
       "soft_pvc                      72       128     9   209\n",
       "soft_tiles                    25        54     2    81\n",
       "tiled                         94        26    29   149\n",
       "wood                          68        47    65   180\n",
       "All                          521       430   138  1089"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "#model_valid_accuracy_comparisons[\"Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jVaYPWv5qrx"
   },
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bx5ogs45qrz"
   },
   "outputs": [],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Logistic Regression\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tbyz6QnG5qr3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-e6KiXFT5qr6"
   },
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCmNBLRg5qr7"
   },
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6tr4dFt5qr7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KmqjeDZ5qr-",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brQ86PiM5qsA"
   },
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PW_MDVJ5qsA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned kNN\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQ0wxQKI5qsC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5356ds75qsD"
   },
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukf8n92x5qsD"
   },
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lu_iAcmG5qsE"
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(300, 100))\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J698SJ-05qsF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6051423324150597\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                carpet       0.50      0.37      0.43        62\n",
      "              concrete       0.57      0.68      0.62       212\n",
      "         fine_concrete       0.51      0.22      0.31        99\n",
      "            hard_tiles       0.00      0.00      0.00         7\n",
      "hard_tiles_large_space       0.65      0.57      0.60        90\n",
      "              soft_pvc       0.62      0.86      0.72       209\n",
      "            soft_tiles       0.48      0.54      0.51        81\n",
      "                 tiled       0.71      0.68      0.70       149\n",
      "                  wood       0.64      0.52      0.57       180\n",
      "\n",
      "           avg / total       0.60      0.61      0.59      1089\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>carpet</th>\n",
       "      <th>concrete</th>\n",
       "      <th>fine_concrete</th>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <th>soft_pvc</th>\n",
       "      <th>soft_tiles</th>\n",
       "      <th>tiled</th>\n",
       "      <th>wood</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carpet</th>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_concrete</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_tiles_large_space</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_pvc</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_tiles</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiled</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>46</td>\n",
       "      <td>251</td>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>289</td>\n",
       "      <td>92</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted               carpet  concrete  fine_concrete  \\\n",
       "True                                                      \n",
       "carpet                      23        11              0   \n",
       "concrete                     5       144              2   \n",
       "fine_concrete                1        28             22   \n",
       "hard_tiles                   0         0              0   \n",
       "hard_tiles_large_space       3        12              3   \n",
       "soft_pvc                     0         9              6   \n",
       "soft_tiles                   2        15              0   \n",
       "tiled                        4        12              0   \n",
       "wood                         8        20             10   \n",
       "All                         46       251             43   \n",
       "\n",
       "Predicted               hard_tiles_large_space  soft_pvc  soft_tiles  tiled  \\\n",
       "True                                                                          \n",
       "carpet                                       4         0           3     11   \n",
       "concrete                                     6        28          11      4   \n",
       "fine_concrete                                7        12           8      8   \n",
       "hard_tiles                                   2         1           0      0   \n",
       "hard_tiles_large_space                      51         8           7      1   \n",
       "soft_pvc                                     1       180           2      7   \n",
       "soft_tiles                                   2        11          44      6   \n",
       "tiled                                        1        15          11    102   \n",
       "wood                                         5        34           6      4   \n",
       "All                                         79       289          92    143   \n",
       "\n",
       "Predicted               wood   All  \n",
       "True                                \n",
       "carpet                    10    62  \n",
       "concrete                  12   212  \n",
       "fine_concrete             13    99  \n",
       "hard_tiles                 4     7  \n",
       "hard_tiles_large_space     5    90  \n",
       "soft_pvc                   4   209  \n",
       "soft_tiles                 1    81  \n",
       "tiled                      4   149  \n",
       "wood                      93   180  \n",
       "All                      146  1089  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "#model_valid_accuracy_comparisons[\"MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOM_lp_t5qsH"
   },
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIpRywYT5qsI"
   },
   "outputs": [],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neural_network.MLPClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned MLP\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOBVpyAj5qsK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816\n",
      "      series_id                 surface\n",
      "0             0                   tiled\n",
      "1             1                concrete\n",
      "2             2                   tiled\n",
      "3             3                    wood\n",
      "4             4                soft_pvc\n",
      "5             5                concrete\n",
      "6             6                concrete\n",
      "7             7                soft_pvc\n",
      "8             8                    wood\n",
      "9             9                    wood\n",
      "10           10                concrete\n",
      "11           11                    wood\n",
      "12           12  hard_tiles_large_space\n",
      "13           13              soft_tiles\n",
      "14           14                soft_pvc\n",
      "15           15                    wood\n",
      "16           16                concrete\n",
      "17           17           fine_concrete\n",
      "18           18                    wood\n",
      "19           19              soft_tiles\n",
      "20           20              soft_tiles\n",
      "21           21                concrete\n",
      "22           22                concrete\n",
      "23           23  hard_tiles_large_space\n",
      "24           24                concrete\n",
      "25           25                    wood\n",
      "26           26              soft_tiles\n",
      "27           27              soft_tiles\n",
      "28           28                    wood\n",
      "29           29                concrete\n",
      "...         ...                     ...\n",
      "3786       3786                    wood\n",
      "3787       3787                concrete\n",
      "3788       3788  hard_tiles_large_space\n",
      "3789       3789                concrete\n",
      "3790       3790           fine_concrete\n",
      "3791       3791                    wood\n",
      "3792       3792                soft_pvc\n",
      "3793       3793                    wood\n",
      "3794       3794                concrete\n",
      "3795       3795                    wood\n",
      "3796       3796              soft_tiles\n",
      "3797       3797                concrete\n",
      "3798       3798                soft_pvc\n",
      "3799       3799                concrete\n",
      "3800       3800  hard_tiles_large_space\n",
      "3801       3801                  carpet\n",
      "3802       3802           fine_concrete\n",
      "3803       3803              soft_tiles\n",
      "3804       3804                concrete\n",
      "3805       3805           fine_concrete\n",
      "3806       3806                concrete\n",
      "3807       3807           fine_concrete\n",
      "3808       3808                   tiled\n",
      "3809       3809  hard_tiles_large_space\n",
      "3810       3810                concrete\n",
      "3811       3811           fine_concrete\n",
      "3812       3812              soft_tiles\n",
      "3813       3813                    wood\n",
      "3814       3814              soft_tiles\n",
      "3815       3815                    wood\n",
      "\n",
      "[3816 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_test)\n",
    "print(len(y_pred))\n",
    "\n",
    "#idx = pd.Int64Index(y_pred)\n",
    "df_op = pd.DataFrame(data =(y_pred))\n",
    "#print(df_op)\n",
    "df_op['series_id'] = range(0, len(df_op))\n",
    "\n",
    "df_op.columns = ['surface', 'series_id']\n",
    "\n",
    "columnsTitles=[\"series_id\", \"surface\"]\n",
    "df_op=df_op.reindex(columns=columnsTitles)\n",
    "print(df_op)\n",
    "\n",
    "df_op.to_csv('sub1.csv', sep=',', index=False)\n",
    "\n",
    "# Print performance details\n",
    "#accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "#model_test_accuracy_comparisons[\"Tuned MLP\"] = accuracy\n",
    "#print(\"Accuracy: \" +  str(accuracy))\n",
    "#print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "#print(\"Confusion Matrix\")\n",
    "#pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "a-riUVvI5qsM"
   },
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8IkttXN5qsM"
   },
   "outputs": [],
   "source": [
    "display(model_test_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlNkZ-Kf5qsP"
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_ZCptPf5qsR"
   },
   "outputs": [],
   "source": [
    "display(model_valid_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzeEVsmq5qsT"
   },
   "outputs": [],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXVkjggp5qsV"
   },
   "outputs": [],
   "source": [
    "display(model_tuned_params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "57P4_L8K5qsX"
   },
   "source": [
    "### Test Best Model On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "N8Bl9YkO5qsY",
    "outputId": "80b0ddaa-7c6d-4203-baf0-42d69396a54b"
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIjhVNSW5qsZ"
   },
   "outputs": [],
   "source": [
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDfgWnpR5qsa"
   },
   "outputs": [],
   "source": [
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdM5rqJk5qsb"
   },
   "outputs": [],
   "source": [
    "my_model = linear_model.LogisticRegression(C=0.4,max_iter = 1000,multi_class='ovr',solver='liblinear')\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vg_QJNyE5qse"
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UstYrkA5qsg"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1 Machine Learning in Python - MNIST Fashion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
